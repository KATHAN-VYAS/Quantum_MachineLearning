{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf283136-e0de-4873-a89d-722a11eabcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "trained with QNI :\n",
    "model saved: best_qni_ccp_model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0e293-999a-442b-8ee7-82d10d09227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**dataset loaded**\n",
      "Quantum epsilon: 0.0270\n",
      "Initial centroids computed\n",
      "Training with QNI-CCP (Feature-space perturbation)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ab9da7984340dda5dfa7bb4af9768d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train L: 2.1540 | Train A: 0.2927 | Val A: 0.3185\n",
      "ðŸ’¾ Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c06ea28934406f8db6be63ee77edf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train L: 1.6501 | Train A: 0.4368 | Val A: 0.4485\n",
      "ðŸ’¾ Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242b57aed9294a079a6e8e10da3a462c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train L: 1.1475 | Train A: 0.5961 | Val A: 0.7476\n",
      "ðŸ’¾ Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115652a410994dd492045261e1cb1544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train L: 0.7293 | Train A: 0.7614 | Val A: 0.7931\n",
      "ðŸ’¾ Saved best model.\n",
      "Centroids recomputed at epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dcdd2ea08e45818ef23a9f59fc96ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train L: 0.4773 | Train A: 0.8362 | Val A: 0.9079\n",
      "ðŸ’¾ Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e472b7d9e4bb4d6285ef8e7866388d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train L: 0.3403 | Train A: 0.8957 | Val A: 0.9426\n",
      "ðŸ’¾ Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a044f4f7a3c4e8896bf65696a1c16f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train L: 0.2478 | Train A: 0.9279 | Val A: 0.9350\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e791d31f44d047c5bc6a09f95ce484e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train L: 0.1976 | Train A: 0.9462 | Val A: 0.9415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6215c4e449d14b6191361ee0f469c59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train L: 0.1657 | Train A: 0.9564 | Val A: 0.9382\n",
      "Centroids recomputed at epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca1f6cb4e244a0788d3be19d42ae18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train L: 0.1462 | Train A: 0.9587 | Val A: 0.9664\n",
      "ðŸ’¾ Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db8ae34e8314bb4ba5c600e6b5e1aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train L: 0.1264 | Train A: 0.9668 | Val A: 0.9697\n",
      "ðŸ’¾ Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ef06fc61934da6a56830768c2582f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train L: 0.1219 | Train A: 0.9672 | Val A: 0.9718\n",
      "ðŸ’¾ Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fb0c1e5a544d2ab73845b11a321bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train L: 0.1138 | Train A: 0.9693 | Val A: 0.9697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd6fe0213f64b10a7b54008048c0e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train L: 0.1117 | Train A: 0.9709 | Val A: 0.9729\n",
      "ðŸ’¾ Saved best model.\n",
      "Centroids recomputed at epoch 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f14f8363a0491aac9032bd6d3ddadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train L: 0.1168 | Train A: 0.9705 | Val A: 0.9707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb02ad8dc644213a0581deef8cb9293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib import pyplot as plt\n",
    "import pennylane as qml\n",
    "from pennylane.qnn import TorchLayer\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_all(42)\n",
    "\n",
    "# ========== DEVICE ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== PARAMETERS ==========\n",
    "n_qubits = 6\n",
    "batch_size = 16\n",
    "num_classes = 25\n",
    "num_epochs = 50\n",
    "lr = 0.0005\n",
    "\n",
    "# ========== TRANSFORMS WITH DATA AUGMENTATION ==========\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# ========== DATASETS ==========\n",
    "train_dataset = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/train', transform=train_transform)\n",
    "val_dataset   = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/val', transform=eval_transform)\n",
    "test_dataset  = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/test', transform=eval_transform)\n",
    "print(\"**dataset loaded**\")\n",
    "\n",
    "# ========== CLASS WEIGHTS ==========\n",
    "labels = [label for _, label in train_dataset.samples]\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(labels),\n",
    "                                     y=labels)\n",
    "class_wts = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# ========== QUANTUM CIRCUIT ==========\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_circuit(inputs, weights):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(inputs[i], wires=i)\n",
    "    \n",
    "    for l in range(weights.shape[0]):\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(weights[l][i], wires=i)\n",
    "        for i in range(n_qubits - 1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "weight_shapes = {\"weights\": (6, n_qubits)}\n",
    "\n",
    "# ========== CNN + QNN MODEL ==========\n",
    "class FeatureReduce(nn.Module):\n",
    "    def __init__(self, final_dim, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),    # 128 -> 64\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),   # 64 -> 32\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 32 -> 16\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # 16 -> 8\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),  # 8 -> 4\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))                # 4Ã—4 -> 1Ã—1\n",
    "        )\n",
    "        self.fc = nn.Linear(128, final_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class HybridQNN(nn.Module):\n",
    "    def __init__(self, n_qubits, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureReduce(final_dim=n_qubits)\n",
    "        self.q_layer = TorchLayer(quantum_circuit, weight_shapes)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_qubits, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.tanh(x)\n",
    "        q_out = torch.stack([self.q_layer(f) for f in x])\n",
    "        return self.classifier(q_out)\n",
    "\n",
    "# ========== PROPER QNI-CCP IMPLEMENTATION ==========\n",
    "\n",
    "def compute_quantum_epsilon(model, n_cnots=30, depth=6, alpha=1.0, beta=1.0):\n",
    "    \"\"\"\n",
    "    Compute epsilon_q based on quantum circuit complexity.\n",
    "    Higher complexity (more CNOTs, deeper) -> smaller epsilon_q\n",
    "    \"\"\"\n",
    "    epsilon_q = 1.0 / (1 + alpha * n_cnots + beta * depth)\n",
    "    return epsilon_q\n",
    "\n",
    "def compute_class_centroids(model, loader, device, num_classes):\n",
    "    \"\"\"\n",
    "    Compute class centroids in the FEATURE SPACE (before quantum layer)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sums = torch.zeros(num_classes, n_qubits, device=device)\n",
    "    counts = torch.zeros(num_classes, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Get features before quantum layer (after feature extractor)\n",
    "            features = model.feature_extractor(x)\n",
    "            features = torch.tanh(features)  # Apply tanh as in forward pass\n",
    "            \n",
    "            for c in range(num_classes):\n",
    "                mask = (y == c)\n",
    "                if mask.any():\n",
    "                    sums[c] += features[mask].sum(0)\n",
    "                    counts[c] += mask.sum()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    counts[counts == 0] = 1\n",
    "    centroids = sums / counts.unsqueeze(1)\n",
    "    return centroids\n",
    "\n",
    "def qni_ccp_perturbation(model, x, y, centroids, epsilon_q=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Proper QNI-CCP implementation as per the paper:\n",
    "    x' = x + epsilon_q * [S âŠ™ (Î¼_c' - x)]\n",
    "    \n",
    "    Where:\n",
    "    - S is the gradient of loss w.r.t. input features\n",
    "    - Î¼_c' is the centroid of target class c'\n",
    "    - âŠ™ is element-wise multiplication\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward pass to get loss and gradients\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 1: Get gradient w.r.t. input (sensitivity map S)\n",
    "    input_grad = x.grad.data  # This is gradient w.r.t. input images\n",
    "    \n",
    "    # We need gradient w.r.t. FEATURES, not input images\n",
    "    # So we need to do a separate forward pass for features\n",
    "    x_feat = x.clone().detach().requires_grad_(True)\n",
    "    features = model.feature_extractor(x_feat)\n",
    "    features = torch.tanh(features)\n",
    "    \n",
    "    # Continue forward pass through quantum and classifier\n",
    "    q_out = torch.stack([model.q_layer(f) for f in features])\n",
    "    logits_feat = model.classifier(q_out)\n",
    "    loss_feat = F.cross_entropy(logits_feat, y)\n",
    "    loss_feat.backward()\n",
    "    \n",
    "    # Step 1: Feature gradient S (gradient w.r.t. features)\n",
    "    S = features.grad.data  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 2: Select target class and get its centroid\n",
    "    if target_class is None:\n",
    "        # Choose a random different class for each sample\n",
    "        target_classes = []\n",
    "        for i in range(y.size(0)):\n",
    "            available_classes = [c for c in range(centroids.size(0)) if c != y[i].item()]\n",
    "            target_classes.append(torch.randint(0, len(available_classes), (1,)).item())\n",
    "            target_classes[-1] = available_classes[target_classes[-1]]\n",
    "        target_class = torch.tensor(target_classes, device=y.device)\n",
    "    else:\n",
    "        target_class = torch.full_like(y, target_class)\n",
    "    \n",
    "    # Get target centroids for each sample\n",
    "    mu_c_prime = centroids[target_class]  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 3: Compute perturbation direction\n",
    "    # We need to perturb in FEATURE space, but we're asked to perturb INPUT\n",
    "    # So we need to map feature perturbation back to input space\n",
    "    \n",
    "    # Feature-space perturbation direction\n",
    "    current_features = features.detach()\n",
    "    feature_direction = mu_c_prime - current_features  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Element-wise multiplication with sensitivity\n",
    "    weighted_direction = S.sign() * feature_direction  # Use sign of gradient\n",
    "    \n",
    "    # For simplicity, we'll perturb in input space using input gradient direction\n",
    "    # but scaled by the feature-space target direction magnitude\n",
    "    direction_magnitude = torch.norm(weighted_direction, dim=1, keepdim=True)\n",
    "    input_direction = input_grad.sign() * direction_magnitude.unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "    # Step 4: Apply perturbation\n",
    "    x_perturbed = x + epsilon_q * input_direction\n",
    "    x_perturbed = torch.clamp(x_perturbed, -1, 1)  # Keep within normalized bounds\n",
    "    \n",
    "    return x_perturbed.detach()\n",
    "\n",
    "def qni_ccp_perturbation(model, x, y, centroids, epsilon_q=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Proper QNI-CCP implementation as per the paper:\n",
    "    x' = x + epsilon_q * [S âŠ™ (Î¼_c' - x)]\n",
    "    \n",
    "    Where:\n",
    "    - S is the gradient of loss w.r.t. input features\n",
    "    - Î¼_c' is the centroid of target class c'\n",
    "    - âŠ™ is element-wise multiplication\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Step 1: Get features and compute gradients w.r.t. features\n",
    "    x_for_features = x.clone().detach().requires_grad_(False)  # Don't need grad for input\n",
    "    \n",
    "    # Forward pass to get features - need to track gradients\n",
    "    features = model.feature_extractor(x_for_features)\n",
    "    features = torch.tanh(features)\n",
    "    features = features.detach().requires_grad_(True)  # Enable gradients for features\n",
    "    \n",
    "    # Continue forward pass through quantum and classifier\n",
    "    q_out = torch.stack([model.q_layer(f) for f in features])\n",
    "    logits = model.classifier(q_out)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    \n",
    "    # Backward pass to get gradients w.r.t. features\n",
    "    loss.backward(retain_graph=True)\n",
    "    \n",
    "    # Check if gradients exist\n",
    "    if features.grad is None:\n",
    "        print(\"Warning: features.grad is None, using zero gradients\")\n",
    "        S = torch.zeros_like(features)\n",
    "    else:\n",
    "        S = features.grad.data  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 2: Select target class and get its centroid\n",
    "    if target_class is None:\n",
    "        # Choose a random different class for each sample\n",
    "        target_classes = []\n",
    "        for i in range(y.size(0)):\n",
    "            available_classes = [c for c in range(centroids.size(0)) if c != y[i].item()]\n",
    "            if available_classes:\n",
    "                target_classes.append(torch.randint(0, len(available_classes), (1,)).item())\n",
    "                target_classes[-1] = available_classes[target_classes[-1]]\n",
    "            else:\n",
    "                target_classes.append((y[i].item() + 1) % centroids.size(0))  # fallback\n",
    "        target_class = torch.tensor(target_classes, device=y.device)\n",
    "    else:\n",
    "        target_class = torch.full_like(y, target_class)\n",
    "    \n",
    "    # Get target centroids for each sample\n",
    "    mu_c_prime = centroids[target_class]  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 3: Compute perturbation in feature space\n",
    "    current_features = features.detach()\n",
    "    feature_direction = mu_c_prime - current_features  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Element-wise multiplication with sensitivity (gradient)\n",
    "    weighted_direction = S * feature_direction  # Element-wise multiplication\n",
    "    \n",
    "    # Now we need to map this back to input space\n",
    "    # We'll use a simplified approach: perturb input in direction of input gradient\n",
    "    # scaled by the magnitude of the feature-space perturbation\n",
    "    \n",
    "    # Get input gradients\n",
    "    x_input = x.clone().detach().requires_grad_(True)\n",
    "    logits_input = model(x_input)\n",
    "    loss_input = F.cross_entropy(logits_input, y)\n",
    "    loss_input.backward()\n",
    "    \n",
    "    if x_input.grad is not None:\n",
    "        input_grad = x_input.grad.data\n",
    "        # Scale by feature perturbation magnitude\n",
    "        perturbation_magnitude = torch.norm(weighted_direction, dim=1, keepdim=True)\n",
    "        # Reshape to match input dimensions\n",
    "        perturbation_magnitude = perturbation_magnitude.unsqueeze(-1).unsqueeze(-1)\n",
    "        input_direction = input_grad.sign() * perturbation_magnitude\n",
    "        \n",
    "        # Apply perturbation\n",
    "        x_perturbed = x + epsilon_q * input_direction\n",
    "        x_perturbed = torch.clamp(x_perturbed, -1, 1)  # Keep within normalized bounds\n",
    "    else:\n",
    "        print(\"Warning: input gradients are None, returning original input\")\n",
    "        x_perturbed = x\n",
    "    \n",
    "    return x_perturbed.detach()\n",
    "\n",
    "\n",
    "def qni_ccp_feature_perturbation_fixed(model, x, y, centroids, epsilon_q=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Alternative: Direct feature-space perturbation for QNI-CCP\n",
    "    This is more direct and avoids the input-space mapping issue\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get original features\n",
    "    with torch.no_grad():\n",
    "        original_features = model.feature_extractor(x)\n",
    "        original_features = torch.tanh(original_features)\n",
    "    \n",
    "    # Create a copy that requires gradients\n",
    "    perturbed_features = original_features.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward pass through quantum and classifier\n",
    "    q_out = torch.stack([model.q_layer(f) for f in perturbed_features])\n",
    "    logits = model.classifier(q_out)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Check if gradients exist\n",
    "    if perturbed_features.grad is None:\n",
    "        print(\"Warning: perturbed_features.grad is None, using zero gradients\")\n",
    "        S = torch.zeros_like(perturbed_features)\n",
    "    else:\n",
    "        S = perturbed_features.grad.data\n",
    "    \n",
    "    # Step 2: Select target class and get centroid\n",
    "    if target_class is None:\n",
    "        # Choose random different class for each sample\n",
    "        target_classes = []\n",
    "        for i in range(y.size(0)):\n",
    "            available_classes = [c for c in range(centroids.size(0)) if c != y[i].item()]\n",
    "            if available_classes:\n",
    "                target_classes.append(torch.randint(0, len(available_classes), (1,)).item())\n",
    "                target_classes[-1] = available_classes[target_classes[-1]]\n",
    "            else:\n",
    "                target_classes.append((y[i].item() + 1) % centroids.size(0))  # fallback\n",
    "        target_class = torch.tensor(target_classes, device=y.device)\n",
    "    else:\n",
    "        target_class = torch.full_like(y, target_class)\n",
    "    \n",
    "    mu_c_prime = centroids[target_class]\n",
    "    \n",
    "    # Step 3: Compute QNI-CCP perturbation\n",
    "    # x' = x + epsilon_q * [S âŠ™ (Î¼_c' - x)]\n",
    "    perturbation_direction = mu_c_prime - original_features\n",
    "    weighted_perturbation = S * perturbation_direction  # Element-wise multiplication\n",
    "    \n",
    "    perturbed_features_final = original_features + epsilon_q * weighted_perturbation\n",
    "    \n",
    "    return perturbed_features_final.detach()\n",
    "\n",
    "\n",
    "# Modified training function that uses the feature-space perturbation\n",
    "def train_with_feature_perturbation(model, train_loader, val_loader, centroids, epsilon_q, num_epochs=50):\n",
    "    \"\"\"\n",
    "    Training function that uses direct feature-space perturbation\n",
    "    \"\"\"\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Recompute centroids every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            centroids = compute_class_centroids(model, train_loader, device, num_classes)\n",
    "            print(f\"Centroids recomputed at epoch {epoch}\")\n",
    "        \n",
    "        model.train()\n",
    "        running_loss, running_corr, running_total = 0, 0, 0\n",
    "        \n",
    "        for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            \n",
    "            # Clean loss\n",
    "            logits_clean = model(xb)\n",
    "            loss_clean = F.cross_entropy(logits_clean, yb)\n",
    "            \n",
    "            # QNI-CCP perturbation in feature space\n",
    "            perturbed_features = qni_ccp_feature_perturbation_fixed(model, xb, yb, centroids, epsilon_q=epsilon_q)\n",
    "            \n",
    "            # Forward pass with perturbed features\n",
    "            q_out = torch.stack([model.q_layer(f) for f in perturbed_features])\n",
    "            logits_qni = model.classifier(q_out)\n",
    "            loss_qni = F.cross_entropy(logits_qni, yb)\n",
    "            \n",
    "            # Centroid regularization (optional)\n",
    "            current_features = model.feature_extractor(xb)\n",
    "            current_features = torch.tanh(current_features)\n",
    "            centroid_reg = ((current_features - centroids[yb])**2).mean()\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = (\n",
    "                0.7 * loss_clean +      # Clean loss\n",
    "                0.2 * loss_qni +        # QNI-CCP loss\n",
    "                0.1 * centroid_reg      # Centroid regularization\n",
    "            )\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            opt.step()\n",
    "            \n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "            running_corr += (logits_clean.argmax(1) == yb).sum().item()\n",
    "            running_total += xb.size(0)\n",
    "        \n",
    "        train_loss = running_loss / running_total\n",
    "        train_acc = running_corr / running_total\n",
    "        sched.step(train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch:2d} | Train L: {train_loss:.4f} | Train A: {train_acc:.4f} | Val A: {val_acc:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_qni_ccp_model.pth\")\n",
    "            print(\"ðŸ’¾ Saved best model.\")\n",
    "    \n",
    "    return best_val_acc\n",
    "# ========== TRAINING FUNCTIONS ==========\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# ========== TRAINING WITH PROPER QNI-CCP ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "\n",
    "# Initialize best validation accuracy\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Compute quantum epsilon based on circuit complexity\n",
    "epsilon_q = compute_quantum_epsilon(model, n_cnots=30, depth=6, alpha=1.0, beta=1.0)\n",
    "print(f\"Quantum epsilon: {epsilon_q:.4f}\")\n",
    "\n",
    "# Compute initial centroids\n",
    "centroids = compute_class_centroids(model, train_loader, device, num_classes)\n",
    "print(\"Initial centroids computed\")\n",
    "\n",
    "# Training loop\n",
    "def qni_ccp_perturbation(model, x, y, centroids, epsilon_q=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Proper QNI-CCP implementation as per the paper:\n",
    "    x' = x + epsilon_q * [S âŠ™ (Î¼_c' - x)]\n",
    "    \n",
    "    Where:\n",
    "    - S is the gradient of loss w.r.t. input features\n",
    "    - Î¼_c' is the centroid of target class c'\n",
    "    - âŠ™ is element-wise multiplication\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Step 1: Get features and compute gradients w.r.t. features\n",
    "    x_for_features = x.clone().detach().requires_grad_(False)  # Don't need grad for input\n",
    "    \n",
    "    # Forward pass to get features - need to track gradients\n",
    "    features = model.feature_extractor(x_for_features)\n",
    "    features = torch.tanh(features)\n",
    "    features = features.detach().requires_grad_(True)  # Enable gradients for features\n",
    "    \n",
    "    # Continue forward pass through quantum and classifier\n",
    "    q_out = torch.stack([model.q_layer(f) for f in features])\n",
    "    logits = model.classifier(q_out)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    \n",
    "    # Backward pass to get gradients w.r.t. features\n",
    "    loss.backward(retain_graph=True)\n",
    "    \n",
    "    # Check if gradients exist\n",
    "    if features.grad is None:\n",
    "        print(\"Warning: features.grad is None, using zero gradients\")\n",
    "        S = torch.zeros_like(features)\n",
    "    else:\n",
    "        S = features.grad.data  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 2: Select target class and get its centroid\n",
    "    if target_class is None:\n",
    "        # Choose a random different class for each sample\n",
    "        target_classes = []\n",
    "        for i in range(y.size(0)):\n",
    "            available_classes = [c for c in range(centroids.size(0)) if c != y[i].item()]\n",
    "            if available_classes:\n",
    "                target_classes.append(torch.randint(0, len(available_classes), (1,)).item())\n",
    "                target_classes[-1] = available_classes[target_classes[-1]]\n",
    "            else:\n",
    "                target_classes.append((y[i].item() + 1) % centroids.size(0))  # fallback\n",
    "        target_class = torch.tensor(target_classes, device=y.device)\n",
    "    else:\n",
    "        target_class = torch.full_like(y, target_class)\n",
    "    \n",
    "    # Get target centroids for each sample\n",
    "    mu_c_prime = centroids[target_class]  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 3: Compute perturbation in feature space\n",
    "    current_features = features.detach()\n",
    "    feature_direction = mu_c_prime - current_features  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Element-wise multiplication with sensitivity (gradient)\n",
    "    weighted_direction = S * feature_direction  # Element-wise multiplication\n",
    "    \n",
    "    # Now we need to map this back to input space\n",
    "    # We'll use a simplified approach: perturb input in direction of input gradient\n",
    "    # scaled by the magnitude of the feature-space perturbation\n",
    "    \n",
    "    # Get input gradients\n",
    "    x_input = x.clone().detach().requires_grad_(True)\n",
    "    logits_input = model(x_input)\n",
    "    loss_input = F.cross_entropy(logits_input, y)\n",
    "    loss_input.backward()\n",
    "    \n",
    "    if x_input.grad is not None:\n",
    "        input_grad = x_input.grad.data\n",
    "        # Scale by feature perturbation magnitude\n",
    "        perturbation_magnitude = torch.norm(weighted_direction, dim=1, keepdim=True)\n",
    "        # Reshape to match input dimensions\n",
    "        perturbation_magnitude = perturbation_magnitude.unsqueeze(-1).unsqueeze(-1)\n",
    "        input_direction = input_grad.sign() * perturbation_magnitude\n",
    "        \n",
    "        # Apply perturbation\n",
    "        x_perturbed = x + epsilon_q * input_direction\n",
    "        x_perturbed = torch.clamp(x_perturbed, -1, 1)  # Keep within normalized bounds\n",
    "    else:\n",
    "        print(\"Warning: input gradients are None, returning original input\")\n",
    "        x_perturbed = x\n",
    "    \n",
    "    return x_perturbed.detach()\n",
    "\n",
    "\n",
    "def qni_ccp_feature_perturbation_fixed(model, x, y, centroids, epsilon_q=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Alternative: Direct feature-space perturbation for QNI-CCP\n",
    "    This is more direct and avoids the input-space mapping issue\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get original features\n",
    "    with torch.no_grad():\n",
    "        original_features = model.feature_extractor(x)\n",
    "        original_features = torch.tanh(original_features)\n",
    "    \n",
    "    # Create a copy that requires gradients\n",
    "    perturbed_features = original_features.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward pass through quantum and classifier\n",
    "    q_out = torch.stack([model.q_layer(f) for f in perturbed_features])\n",
    "    logits = model.classifier(q_out)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Check if gradients exist\n",
    "    if perturbed_features.grad is None:\n",
    "        print(\"Warning: perturbed_features.grad is None, using zero gradients\")\n",
    "        S = torch.zeros_like(perturbed_features)\n",
    "    else:\n",
    "        S = perturbed_features.grad.data\n",
    "    \n",
    "    # Step 2: Select target class and get centroid\n",
    "    if target_class is None:\n",
    "        # Choose random different class for each sample\n",
    "        target_classes = []\n",
    "        for i in range(y.size(0)):\n",
    "            available_classes = [c for c in range(centroids.size(0)) if c != y[i].item()]\n",
    "            if available_classes:\n",
    "                target_classes.append(torch.randint(0, len(available_classes), (1,)).item())\n",
    "                target_classes[-1] = available_classes[target_classes[-1]]\n",
    "            else:\n",
    "                target_classes.append((y[i].item() + 1) % centroids.size(0))  # fallback\n",
    "        target_class = torch.tensor(target_classes, device=y.device)\n",
    "    else:\n",
    "        target_class = torch.full_like(y, target_class)\n",
    "    \n",
    "    mu_c_prime = centroids[target_class]\n",
    "    \n",
    "    # Step 3: Compute QNI-CCP perturbation\n",
    "    # x' = x + epsilon_q * [S âŠ™ (Î¼_c' - x)]\n",
    "    perturbation_direction = mu_c_prime - original_features\n",
    "    weighted_perturbation = S * perturbation_direction  # Element-wise multiplication\n",
    "    \n",
    "    perturbed_features_final = original_features + epsilon_q * weighted_perturbation\n",
    "    \n",
    "    return perturbed_features_final.detach()\n",
    "\n",
    "\n",
    "# Replace the original training loop with this:\n",
    "print(\"Training with QNI-CCP (Feature-space perturbation)...\")\n",
    "best_val_acc = train_with_feature_perturbation(model, train_loader, val_loader, centroids, epsilon_q, num_epochs)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
