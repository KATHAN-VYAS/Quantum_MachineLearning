{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d0caf-ca48-402e-ab24-17094562b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "QNI + adversarial (claude)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa0e293-999a-442b-8ee7-82d10d09227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**dataset loaded**\n",
      "Quantum epsilon: 0.0270\n",
      "Initial centroids computed\n",
      "Training with QNI-CCP (Feature-space perturbation)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78df89440344c34b0d247a756c06422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train L: 2.1570 | Train A: 0.2920 | Val A: 0.3619\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687fdf8f6c5a49a7841ed7e54f5ec266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train L: 1.5573 | Train A: 0.4309 | Val A: 0.4496\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490b6482a40a4403a754d3f644e7a831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train L: 1.1747 | Train A: 0.5916 | Val A: 0.4875\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31103dc70ace49f69fd19ea19e68e2e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train L: 0.9429 | Train A: 0.6927 | Val A: 0.6511\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314ffdcfe5e743289fbd53dc2ecfb3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train L: 0.7959 | Train A: 0.7355 | Val A: 0.7703\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d11185ff5b143418102e8ed21b1c260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train L: 0.7036 | Train A: 0.7647 | Val A: 0.7866\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a545571f94cb4f31b4ffb4c9a3f3e67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train L: 0.6330 | Train A: 0.7926 | Val A: 0.8028\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7316ea04c4b14d329b48c99d3e0c14e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train L: 0.5429 | Train A: 0.8320 | Val A: 0.8559\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b480ec9e9e1748c9894309332be2feea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train L: 0.4764 | Train A: 0.8653 | Val A: 0.8830\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee49f29e3f4457386c8de6164e719ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 711\u001b[0m\n\u001b[1;32m    708\u001b[0m centroids \u001b[38;5;241m=\u001b[39m compute_class_centroids(model, train_loader, device, num_classes)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# now train\u001b[39;00m\n\u001b[0;32m--> 711\u001b[0m best_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_feature_perturbation_and_adv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_q\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon_fgsm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_pgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_pgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters_pgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m    717\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest val acc:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_val)\n",
      "Cell \u001b[0;32mIn[1], line 468\u001b[0m, in \u001b[0;36mtrain_with_feature_perturbation_and_adv\u001b[0;34m(model, train_loader, val_loader, centroids, epsilon_q, epsilon_fgsm, eps_pgd, alpha_pgd, iters_pgd, num_epochs)\u001b[0m\n\u001b[1;32m    465\u001b[0m loss_clean   \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits_clean, yb)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# 2) QNI‑CCP perturbation in feature space\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m perturbed_features \u001b[38;5;241m=\u001b[39m \u001b[43mqni_ccp_feature_perturbation_fixed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon_q\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m q_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([model\u001b[38;5;241m.\u001b[39mq_layer(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m perturbed_features])\n\u001b[1;32m    472\u001b[0m logits_qni \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mclassifier(q_out)\n",
      "Cell \u001b[0;32mIn[1], line 668\u001b[0m, in \u001b[0;36mqni_ccp_feature_perturbation_fixed\u001b[0;34m(model, x, y, centroids, epsilon_q, target_class)\u001b[0m\n\u001b[1;32m    666\u001b[0m logits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mclassifier(q_out)\n\u001b[1;32m    667\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y)\n\u001b[0;32m--> 668\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;66;03m# Check if gradients exist\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m perturbed_features\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib import pyplot as plt\n",
    "import pennylane as qml\n",
    "from pennylane.qnn import TorchLayer\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_all(42)\n",
    "\n",
    "# ========== DEVICE ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== PARAMETERS ==========\n",
    "n_qubits = 6\n",
    "batch_size = 16\n",
    "num_classes = 25\n",
    "num_epochs = 50\n",
    "lr = 0.0005\n",
    "\n",
    "# ========== TRANSFORMS WITH DATA AUGMENTATION ==========\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# ========== DATASETS ==========\n",
    "train_dataset = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/train', transform=train_transform)\n",
    "val_dataset   = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/val', transform=eval_transform)\n",
    "test_dataset  = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/test', transform=eval_transform)\n",
    "print(\"**dataset loaded**\")\n",
    "\n",
    "# ========== CLASS WEIGHTS ==========\n",
    "labels = [label for _, label in train_dataset.samples]\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(labels),\n",
    "                                     y=labels)\n",
    "class_wts = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# ========== QUANTUM CIRCUIT ==========\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_circuit(inputs, weights):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(inputs[i], wires=i)\n",
    "    \n",
    "    for l in range(weights.shape[0]):\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(weights[l][i], wires=i)\n",
    "        for i in range(n_qubits - 1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "weight_shapes = {\"weights\": (6, n_qubits)}\n",
    "\n",
    "# ========== CNN + QNN MODEL ==========\n",
    "class FeatureReduce(nn.Module):\n",
    "    def __init__(self, final_dim, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),    # 128 -> 64\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),   # 64 -> 32\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 32 -> 16\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # 16 -> 8\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),  # 8 -> 4\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))                # 4×4 -> 1×1\n",
    "        )\n",
    "        self.fc = nn.Linear(128, final_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class HybridQNN(nn.Module):\n",
    "    def __init__(self, n_qubits, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureReduce(final_dim=n_qubits)\n",
    "        self.q_layer = TorchLayer(quantum_circuit, weight_shapes)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_qubits, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.tanh(x)\n",
    "        q_out = torch.stack([self.q_layer(f) for f in x])\n",
    "        return self.classifier(q_out)\n",
    "\n",
    "# ========== PROPER QNI-CCP IMPLEMENTATION ==========\n",
    "\n",
    "def compute_quantum_epsilon(model, n_cnots=30, depth=6, alpha=1.0, beta=1.0):\n",
    "    \"\"\"\n",
    "    Compute epsilon_q based on quantum circuit complexity.\n",
    "    Higher complexity (more CNOTs, deeper) -> smaller epsilon_q\n",
    "    \"\"\"\n",
    "    epsilon_q = 1.0 / (1 + alpha * n_cnots + beta * depth)\n",
    "    return epsilon_q\n",
    "\n",
    "def compute_class_centroids(model, loader, device, num_classes):\n",
    "    \"\"\"\n",
    "    Compute class centroids in the FEATURE SPACE (before quantum layer)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sums = torch.zeros(num_classes, n_qubits, device=device)\n",
    "    counts = torch.zeros(num_classes, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Get features before quantum layer (after feature extractor)\n",
    "            features = model.feature_extractor(x)\n",
    "            features = torch.tanh(features)  # Apply tanh as in forward pass\n",
    "            \n",
    "            for c in range(num_classes):\n",
    "                mask = (y == c)\n",
    "                if mask.any():\n",
    "                    sums[c] += features[mask].sum(0)\n",
    "                    counts[c] += mask.sum()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    counts[counts == 0] = 1\n",
    "    centroids = sums / counts.unsqueeze(1)\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def qni_ccp_perturbation(model, x, y, centroids, epsilon_q=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Proper QNI-CCP implementation as per the paper:\n",
    "    x' = x + epsilon_q * [S ⊙ (μ_c' - x)]\n",
    "    \n",
    "    Where:\n",
    "    - S is the gradient of loss w.r.t. input features\n",
    "    - μ_c' is the centroid of target class c'\n",
    "    - ⊙ is element-wise multiplication\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Step 1: Get features and compute gradients w.r.t. features\n",
    "    x_for_features = x.clone().detach().requires_grad_(False)  # Don't need grad for input\n",
    "    \n",
    "    # Forward pass to get features - need to track gradients\n",
    "    features = model.feature_extractor(x_for_features)\n",
    "    features = torch.tanh(features)\n",
    "    features = features.detach().requires_grad_(True)  # Enable gradients for features\n",
    "    \n",
    "    # Continue forward pass through quantum and classifier\n",
    "    q_out = torch.stack([model.q_layer(f) for f in features])\n",
    "    logits = model.classifier(q_out)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    \n",
    "    # Backward pass to get gradients w.r.t. features\n",
    "    loss.backward(retain_graph=True)\n",
    "    \n",
    "    # Check if gradients exist\n",
    "    if features.grad is None:\n",
    "        print(\"Warning: features.grad is None, using zero gradients\")\n",
    "        S = torch.zeros_like(features)\n",
    "    else:\n",
    "        S = features.grad.data  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 2: Select target class and get its centroid\n",
    "    if target_class is None:\n",
    "        # Choose a random different class for each sample\n",
    "        target_classes = []\n",
    "        for i in range(y.size(0)):\n",
    "            available_classes = [c for c in range(centroids.size(0)) if c != y[i].item()]\n",
    "            if available_classes:\n",
    "                target_classes.append(torch.randint(0, len(available_classes), (1,)).item())\n",
    "                target_classes[-1] = available_classes[target_classes[-1]]\n",
    "            else:\n",
    "                target_classes.append((y[i].item() + 1) % centroids.size(0))  # fallback\n",
    "        target_class = torch.tensor(target_classes, device=y.device)\n",
    "    else:\n",
    "        target_class = torch.full_like(y, target_class)\n",
    "    \n",
    "    # Get target centroids for each sample\n",
    "    mu_c_prime = centroids[target_class]  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 3: Compute perturbation in feature space\n",
    "    current_features = features.detach()\n",
    "    feature_direction = mu_c_prime - current_features  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Element-wise multiplication with sensitivity (gradient)\n",
    "    weighted_direction = S * feature_direction  # Element-wise multiplication\n",
    "    \n",
    "    # Now we need to map this back to input space\n",
    "    # We'll use a simplified approach: perturb input in direction of input gradient\n",
    "    # scaled by the magnitude of the feature-space perturbation\n",
    "    \n",
    "    # Get input gradients\n",
    "    x_input = x.clone().detach().requires_grad_(True)\n",
    "    logits_input = model(x_input)\n",
    "    loss_input = F.cross_entropy(logits_input, y)\n",
    "    loss_input.backward()\n",
    "    \n",
    "    if x_input.grad is not None:\n",
    "        input_grad = x_input.grad.data\n",
    "        # Scale by feature perturbation magnitude\n",
    "        perturbation_magnitude = torch.norm(weighted_direction, dim=1, keepdim=True)\n",
    "        # Reshape to match input dimensions\n",
    "        perturbation_magnitude = perturbation_magnitude.unsqueeze(-1).unsqueeze(-1)\n",
    "        input_direction = input_grad.sign() * perturbation_magnitude\n",
    "        \n",
    "        # Apply perturbation\n",
    "        x_perturbed = x + epsilon_q * input_direction\n",
    "        x_perturbed = torch.clamp(x_perturbed, -1, 1)  # Keep within normalized bounds\n",
    "    else:\n",
    "        print(\"Warning: input gradients are None, returning original input\")\n",
    "        x_perturbed = x\n",
    "    \n",
    "    return x_perturbed.detach()\n",
    "\n",
    "\n",
    "def qni_ccp_feature_perturbation_fixed(model, x, y, centroids, epsilon_q=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Alternative: Direct feature-space perturbation for QNI-CCP\n",
    "    This is more direct and avoids the input-space mapping issue\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get original features\n",
    "    with torch.no_grad():\n",
    "        original_features = model.feature_extractor(x)\n",
    "        original_features = torch.tanh(original_features)\n",
    "    \n",
    "    # Create a copy that requires gradients\n",
    "    perturbed_features = original_features.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward pass through quantum and classifier\n",
    "    q_out = torch.stack([model.q_layer(f) for f in perturbed_features])\n",
    "    logits = model.classifier(q_out)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Check if gradients exist\n",
    "    if perturbed_features.grad is None:\n",
    "        print(\"Warning: perturbed_features.grad is None, using zero gradients\")\n",
    "        S = torch.zeros_like(perturbed_features)\n",
    "    else:\n",
    "        S = perturbed_features.grad.data\n",
    "    \n",
    "    # Step 2: Select target class and get centroid\n",
    "    if target_class is None:\n",
    "        # Choose random different class for each sample\n",
    "        target_classes = []\n",
    "        for i in range(y.size(0)):\n",
    "            available_classes = [c for c in range(centroids.size(0)) if c != y[i].item()]\n",
    "            if available_classes:\n",
    "                target_classes.append(torch.randint(0, len(available_classes), (1,)).item())\n",
    "                target_classes[-1] = available_classes[target_classes[-1]]\n",
    "            else:\n",
    "                target_classes.append((y[i].item() + 1) % centroids.size(0))  # fallback\n",
    "        target_class = torch.tensor(target_classes, device=y.device)\n",
    "    else:\n",
    "        target_class = torch.full_like(y, target_class)\n",
    "    \n",
    "    mu_c_prime = centroids[target_class]\n",
    "    \n",
    "    # Step 3: Compute QNI-CCP perturbation\n",
    "    # x' = x + epsilon_q * [S ⊙ (μ_c' - x)]\n",
    "    perturbation_direction = mu_c_prime - original_features\n",
    "    weighted_perturbation = S * perturbation_direction  # Element-wise multiplication\n",
    "    \n",
    "    perturbed_features_final = original_features + epsilon_q * weighted_perturbation\n",
    "    \n",
    "    return perturbed_features_final.detach()\n",
    "\n",
    "def fgsm_attack(model, images, labels, eps_fgsm=0.03, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate FGSM adversarial examples.\n",
    "    \n",
    "    Args:\n",
    "        model     : your neural network\n",
    "        images    : clean input batch, shape [B, C, H, W]\n",
    "        labels    : true labels for images, shape [B]\n",
    "        eps_fgsm  : perturbation magnitude (ε)\n",
    "        device    : 'cuda' or 'cpu'\n",
    "    \n",
    "    Returns:\n",
    "        images_adv: adversarial images in the same shape\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # make a copy that requires gradient\n",
    "    images_adv = images.clone().detach().to(device).requires_grad_(True)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # forward + backward\n",
    "    logits = model(images_adv)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # take a single step in the sign‐gradient direction\n",
    "    images_adv = images_adv + eps_fgsm * images_adv.grad.sign()\n",
    "    # clamp to valid range\n",
    "    images_adv = torch.clamp(images_adv, min=-1.0, max=1.0)\n",
    "    return images_adv.detach()\n",
    "\n",
    "\n",
    "def pgd_attack(model,\n",
    "               images,\n",
    "               labels,\n",
    "               pgd_eps=0.1,\n",
    "               pgd_alpha=0.01,\n",
    "               pgd_iters=7,\n",
    "               device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate PGD adversarial examples.\n",
    "    \n",
    "    Args:\n",
    "        model      : your neural network\n",
    "        images     : clean input batch, shape [B, C, H, W]\n",
    "        labels     : true labels for images, shape [B]\n",
    "        pgd_eps    : maximum total perturbation (ℓ∞ radius)\n",
    "        pgd_alpha  : step size per iteration\n",
    "        pgd_iters  : number of iterations\n",
    "        device     : 'cuda' or 'cpu'\n",
    "    \n",
    "    Returns:\n",
    "        images_adv : adversarial images in the same shape\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    images_orig = images.clone().detach().to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # start from a random point in the eps‐ball\n",
    "    images_adv = images_orig + torch.empty_like(images_orig).uniform_(-pgd_eps, pgd_eps)\n",
    "    images_adv = torch.clamp(images_adv, -1.0, 1.0).detach()\n",
    "\n",
    "    for _ in range(pgd_iters):\n",
    "        images_adv.requires_grad_(True)\n",
    "        logits = model(images_adv)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient step\n",
    "        perturb = pgd_alpha * images_adv.grad.sign()\n",
    "        images_adv = images_adv + perturb\n",
    "\n",
    "        # project back into the ℓ∞-ball around the original images\n",
    "        delta = torch.clamp(images_adv - images_orig, min=-pgd_eps, max=pgd_eps)\n",
    "        images_adv = torch.clamp(images_orig + delta, -1.0, 1.0).detach()\n",
    "\n",
    "    return images_adv\n",
    "\n",
    "\n",
    "# Modified training function that uses the feature-space perturbation\n",
    "def train_with_feature_perturbation_and_adv(model,\n",
    "                                            train_loader,\n",
    "                                            val_loader,\n",
    "                                            centroids,\n",
    "                                            epsilon_q,\n",
    "                                            epsilon_fgsm=0.03,\n",
    "                                            eps_pgd=0.1,\n",
    "                                            alpha_pgd=0.01,\n",
    "                                            iters_pgd=7,\n",
    "                                            num_epochs=50):\n",
    "    \"\"\"\n",
    "    Training that combines:\n",
    "      • Clean loss\n",
    "      • QNI‑CCP feature‑space perturbation loss\n",
    "      • FGSM adversarial loss\n",
    "      • PGD adversarial loss\n",
    "      • Optional centroid regularization\n",
    "    \"\"\"\n",
    "    opt   = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Recompute centroids every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            centroids = compute_class_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "        model.train()\n",
    "        running_loss, running_corr, running_total = 0, 0, 0\n",
    "\n",
    "        for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            # 1) Clean loss\n",
    "            logits_clean = model(xb)\n",
    "            loss_clean   = F.cross_entropy(logits_clean, yb)\n",
    "\n",
    "            # 2) QNI‑CCP perturbation in feature space\n",
    "            perturbed_features = qni_ccp_feature_perturbation_fixed(\n",
    "                model, xb, yb, centroids, epsilon_q=epsilon_q\n",
    "            )\n",
    "            q_out = torch.stack([model.q_layer(f) for f in perturbed_features])\n",
    "            logits_qni = model.classifier(q_out)\n",
    "            loss_qni   = F.cross_entropy(logits_qni, yb)\n",
    "\n",
    "            # 3) FGSM adversarial loss\n",
    "            xb_fgsm   = fgsm_attack(model, xb, yb, eps_fgsm=epsilon_fgsm)\n",
    "\n",
    "            logits_fgsm = model(xb_fgsm)\n",
    "            loss_fgsm  = F.cross_entropy(logits_fgsm, yb)\n",
    "\n",
    "            # 4) PGD adversarial loss\n",
    "            xb_pgd = pgd_attack(\n",
    "            model, xb, yb,\n",
    "            pgd_eps=eps_pgd,\n",
    "            pgd_alpha=alpha_pgd,\n",
    "            pgd_iters=iters_pgd\n",
    "        )\n",
    "\n",
    "            logits_pgd  = model(xb_pgd)\n",
    "            loss_pgd   = F.cross_entropy(logits_pgd, yb)\n",
    "\n",
    "            # 5) Centroid regularization (optional)\n",
    "            current_features = torch.tanh(model.feature_extractor(xb))\n",
    "            centroid_reg     = ((current_features - centroids[yb])**2).mean()\n",
    "\n",
    "            # Combine all losses with weights\n",
    "            loss = (\n",
    "                0.5 * loss_clean   +  # clean\n",
    "                0.15 * loss_qni    +  # QNI‑CCP\n",
    "                0.1  * loss_fgsm   +  # FGSM\n",
    "                0.15 * loss_pgd    +  # PGD\n",
    "                0.1  * centroid_reg   # centroid reg\n",
    "            )\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            opt.step()\n",
    "\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "            running_corr += (logits_clean.argmax(1) == yb).sum().item()\n",
    "            running_total += xb.size(0)\n",
    "\n",
    "        train_loss = running_loss / running_total\n",
    "        train_acc  = running_corr / running_total\n",
    "        sched.step(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        print(f\"Epoch {epoch:2d} | Train L: {train_loss:.4f} | \"\n",
    "              f\"Train A: {train_acc:.4f} | Val A: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_qni_ccp_adv_model.pth\")\n",
    "            print(\"💾 Saved best model.\")\n",
    "\n",
    "    return best_val_acc\n",
    "\n",
    "# ========== TRAINING FUNCTIONS ==========\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# ========== TRAINING WITH PROPER QNI-CCP ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "\n",
    "# Initialize best validation accuracy\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Compute quantum epsilon based on circuit complexity\n",
    "epsilon_q = compute_quantum_epsilon(model, n_cnots=30, depth=6, alpha=1.0, beta=1.0)\n",
    "print(f\"Quantum epsilon: {epsilon_q:.4f}\")\n",
    "\n",
    "# Compute initial centroids\n",
    "centroids = compute_class_centroids(model, train_loader, device, num_classes)\n",
    "print(\"Initial centroids computed\")\n",
    "\n",
    "# Training loop\n",
    "def qni_ccp_perturbation(model, x, y, centroids, epsilon_q=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Proper QNI-CCP implementation as per the paper:\n",
    "    x' = x + epsilon_q * [S ⊙ (μ_c' - x)]\n",
    "    \n",
    "    Where:\n",
    "    - S is the gradient of loss w.r.t. input features\n",
    "    - μ_c' is the centroid of target class c'\n",
    "    - ⊙ is element-wise multiplication\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Step 1: Get features and compute gradients w.r.t. features\n",
    "    x_for_features = x.clone().detach().requires_grad_(False)  # Don't need grad for input\n",
    "    \n",
    "    # Forward pass to get features - need to track gradients\n",
    "    features = model.feature_extractor(x_for_features)\n",
    "    features = torch.tanh(features)\n",
    "    features = features.detach().requires_grad_(True)  # Enable gradients for features\n",
    "    \n",
    "    # Continue forward pass through quantum and classifier\n",
    "    q_out = torch.stack([model.q_layer(f) for f in features])\n",
    "    logits = model.classifier(q_out)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    \n",
    "    # Backward pass to get gradients w.r.t. features\n",
    "    loss.backward(retain_graph=True)\n",
    "    \n",
    "    # Check if gradients exist\n",
    "    if features.grad is None:\n",
    "        print(\"Warning: features.grad is None, using zero gradients\")\n",
    "        S = torch.zeros_like(features)\n",
    "    else:\n",
    "        S = features.grad.data  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 2: Select target class and get its centroid\n",
    "    if target_class is None:\n",
    "        # Choose a random different class for each sample\n",
    "        target_classes = []\n",
    "        for i in range(y.size(0)):\n",
    "            available_classes = [c for c in range(centroids.size(0)) if c != y[i].item()]\n",
    "            if available_classes:\n",
    "                target_classes.append(torch.randint(0, len(available_classes), (1,)).item())\n",
    "                target_classes[-1] = available_classes[target_classes[-1]]\n",
    "            else:\n",
    "                target_classes.append((y[i].item() + 1) % centroids.size(0))  # fallback\n",
    "        target_class = torch.tensor(target_classes, device=y.device)\n",
    "    else:\n",
    "        target_class = torch.full_like(y, target_class)\n",
    "    \n",
    "    # Get target centroids for each sample\n",
    "    mu_c_prime = centroids[target_class]  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Step 3: Compute perturbation in feature space\n",
    "    current_features = features.detach()\n",
    "    feature_direction = mu_c_prime - current_features  # Shape: [batch_size, n_qubits]\n",
    "    \n",
    "    # Element-wise multiplication with sensitivity (gradient)\n",
    "    weighted_direction = S * feature_direction  # Element-wise multiplication\n",
    "    \n",
    "    # Now we need to map this back to input space\n",
    "    # We'll use a simplified approach: perturb input in direction of input gradient\n",
    "    # scaled by the magnitude of the feature-space perturbation\n",
    "    \n",
    "    # Get input gradients\n",
    "    x_input = x.clone().detach().requires_grad_(True)\n",
    "    logits_input = model(x_input)\n",
    "    loss_input = F.cross_entropy(logits_input, y)\n",
    "    loss_input.backward()\n",
    "    \n",
    "    if x_input.grad is not None:\n",
    "        input_grad = x_input.grad.data\n",
    "        # Scale by feature perturbation magnitude\n",
    "        perturbation_magnitude = torch.norm(weighted_direction, dim=1, keepdim=True)\n",
    "        # Reshape to match input dimensions\n",
    "        perturbation_magnitude = perturbation_magnitude.unsqueeze(-1).unsqueeze(-1)\n",
    "        input_direction = input_grad.sign() * perturbation_magnitude\n",
    "        \n",
    "        # Apply perturbation\n",
    "        x_perturbed = x + epsilon_q * input_direction\n",
    "        x_perturbed = torch.clamp(x_perturbed, -1, 1)  # Keep within normalized bounds\n",
    "    else:\n",
    "        print(\"Warning: input gradients are None, returning original input\")\n",
    "        x_perturbed = x\n",
    "    \n",
    "    return x_perturbed.detach()\n",
    "\n",
    "\n",
    "def qni_ccp_feature_perturbation_fixed(model, x, y, centroids, epsilon_q=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Alternative: Direct feature-space perturbation for QNI-CCP\n",
    "    This is more direct and avoids the input-space mapping issue\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get original features\n",
    "    with torch.no_grad():\n",
    "        original_features = model.feature_extractor(x)\n",
    "        original_features = torch.tanh(original_features)\n",
    "    \n",
    "    # Create a copy that requires gradients\n",
    "    perturbed_features = original_features.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward pass through quantum and classifier\n",
    "    q_out = torch.stack([model.q_layer(f) for f in perturbed_features])\n",
    "    logits = model.classifier(q_out)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Check if gradients exist\n",
    "    if perturbed_features.grad is None:\n",
    "        print(\"Warning: perturbed_features.grad is None, using zero gradients\")\n",
    "        S = torch.zeros_like(perturbed_features)\n",
    "    else:\n",
    "        S = perturbed_features.grad.data\n",
    "    \n",
    "    # Step 2: Select target class and get centroid\n",
    "    if target_class is None:\n",
    "        # Choose random different class for each sample\n",
    "        target_classes = []\n",
    "        for i in range(y.size(0)):\n",
    "            available_classes = [c for c in range(centroids.size(0)) if c != y[i].item()]\n",
    "            if available_classes:\n",
    "                target_classes.append(torch.randint(0, len(available_classes), (1,)).item())\n",
    "                target_classes[-1] = available_classes[target_classes[-1]]\n",
    "            else:\n",
    "                target_classes.append((y[i].item() + 1) % centroids.size(0))  # fallback\n",
    "        target_class = torch.tensor(target_classes, device=y.device)\n",
    "    else:\n",
    "        target_class = torch.full_like(y, target_class)\n",
    "    \n",
    "    mu_c_prime = centroids[target_class]\n",
    "    \n",
    "    # Step 3: Compute QNI-CCP perturbation\n",
    "    # x' = x + epsilon_q * [S ⊙ (μ_c' - x)]\n",
    "    perturbation_direction = mu_c_prime - original_features\n",
    "    weighted_perturbation = S * perturbation_direction  # Element-wise multiplication\n",
    "    \n",
    "    perturbed_features_final = original_features + epsilon_q * weighted_perturbation\n",
    "    \n",
    "    return perturbed_features_final.detach()\n",
    "\n",
    "\n",
    "# Replace the original training loop with this:\n",
    "print(\"Training with QNI-CCP (Feature-space perturbation)...\")\n",
    "# before training\n",
    "epsilon_q = compute_quantum_epsilon(model, n_cnots=30, depth=6)\n",
    "centroids = compute_class_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "# now train\n",
    "best_val = train_with_feature_perturbation_and_adv(\n",
    "    model, train_loader, val_loader,\n",
    "    centroids, epsilon_q,\n",
    "    epsilon_fgsm=0.03,\n",
    "    eps_pgd=0.1, alpha_pgd=0.01, iters_pgd=7,\n",
    "    num_epochs=50\n",
    ")\n",
    "print(\"Best val acc:\", best_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d013b972-f1d3-4c75-a98b-a79bb63ec3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded from qni_ccp_adv_model_epoch_10.pth\n",
      "Resuming training...\n",
      "Quantum epsilon: 0.0270\n",
      "Centroids computed\n",
      "Initial validation accuracy: 0.9339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab320cd78394184982e3180763de662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train L: 0.2296 | Train A: 0.9449 | Val A: 0.7692\n",
      "💾 Saved model for epoch 11\n",
      "🏆 New best model saved with val_acc: 0.7692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ef8664753f4de29f8bddf383bc889a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train L: 0.2243 | Train A: 0.9434 | Val A: 0.9415\n",
      "💾 Saved model for epoch 12\n",
      "🏆 New best model saved with val_acc: 0.9415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7215f30fe54aa38cdd3c1f1f3cbdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train L: 0.2097 | Train A: 0.9460 | Val A: 0.9469\n",
      "💾 Saved model for epoch 13\n",
      "🏆 New best model saved with val_acc: 0.9469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824bb159548d4014b3823e6331d04e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train L: 0.2021 | Train A: 0.9513 | Val A: 0.9437\n",
      "💾 Saved model for epoch 14\n",
      "🏆 New best model saved with val_acc: 0.9437\n",
      "Recomputed centroids at epoch 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bb272ab8214dcdbd4e12be12a98a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train L: 0.2090 | Train A: 0.9512 | Val A: 0.7844\n",
      "💾 Saved model for epoch 15\n",
      "🏆 New best model saved with val_acc: 0.7844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8903885b33c414dbf485a6005a665c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train L: 0.1935 | Train A: 0.9529 | Val A: 0.9393\n",
      "💾 Saved model for epoch 16\n",
      "🏆 New best model saved with val_acc: 0.9393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b75d51fc444dbdb1be51f3971dcdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train L: 0.1779 | Train A: 0.9548 | Val A: 0.9512\n",
      "💾 Saved model for epoch 17\n",
      "🏆 New best model saved with val_acc: 0.9512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b84ff290b3e43d894a6abd5582198c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train L: 0.1655 | Train A: 0.9598 | Val A: 0.9599\n",
      "💾 Saved model for epoch 21\n",
      "🏆 New best model saved with val_acc: 0.9599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f32b39a73ed44b2bc1cf2f79fda0a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train L: 0.1626 | Train A: 0.9610 | Val A: 0.9393\n",
      "💾 Saved model for epoch 22\n",
      "🏆 New best model saved with val_acc: 0.9393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1e2e5181fe4667a055d880cf06efa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train L: 0.1584 | Train A: 0.9603 | Val A: 0.9577\n",
      "💾 Saved model for epoch 23\n",
      "🏆 New best model saved with val_acc: 0.9577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5139176f220d4ed3b2c6a5673f995454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 195\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCentroids computed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Resume training for 15 more epochs\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m best_val_resumed \u001b[38;5;241m=\u001b[39m \u001b[43mresume_training_with_feature_perturbation_and_adv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_q\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon_fgsm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_pgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_pgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters_pgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can adjust this if you know the exact epoch number\u001b[39;49;00m\n\u001b[1;32m    202\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Training resumed and completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal best validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_resumed\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 136\u001b[0m, in \u001b[0;36mresume_training_with_feature_perturbation_and_adv\u001b[0;34m(model, train_loader, val_loader, centroids, epsilon_q, epsilon_fgsm, eps_pgd, alpha_pgd, iters_pgd, num_epochs, start_epoch)\u001b[0m\n\u001b[1;32m    127\u001b[0m loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m loss_clean \u001b[38;5;241m+\u001b[39m    \u001b[38;5;66;03m# clean\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;241m0.15\u001b[39m \u001b[38;5;241m*\u001b[39m loss_qni \u001b[38;5;241m+\u001b[39m     \u001b[38;5;66;03m# QNI-CCP\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m centroid_reg    \u001b[38;5;66;03m# centroid reg\u001b[39;00m\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    135\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 136\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    138\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Resume training from saved model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# Make sure all your model classes and functions are defined before this\n",
    "# (FocalLoss, HybridQNN, FeatureReduce, etc. - all from your original code)\n",
    "\n",
    "# ========== RESUME TRAINING SETUP ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Recreate the model architecture (same as original)\n",
    "n_qubits = 6\n",
    "num_classes = 25\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "\n",
    "# Load the saved model weights\n",
    "model_path = \"qni_ccp_adv_model_epoch_10.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  # ✅ fixed here\n",
    "    print(f\"✅ Model loaded from {model_path}\")\n",
    "else:\n",
    "    print(f\"❌ Model file {model_path} not found!\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Recreate data loaders (same as original)\n",
    "batch_size = 16\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/train', transform=train_transform)\n",
    "val_dataset = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/val', transform=eval_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# ========== MODIFIED TRAINING FUNCTION FOR RESUME ==========\n",
    "def resume_training_with_feature_perturbation_and_adv(model,\n",
    "                                                     train_loader,\n",
    "                                                     val_loader,\n",
    "                                                     centroids,\n",
    "                                                     epsilon_q,\n",
    "                                                     epsilon_fgsm=0.03,\n",
    "                                                     eps_pgd=0.1,\n",
    "                                                     alpha_pgd=0.01,\n",
    "                                                     iters_pgd=7,\n",
    "                                                     num_epochs=15,\n",
    "                                                     start_epoch=11):\n",
    "    \"\"\"\n",
    "    Resume training with model saving after each epoch\n",
    "    \"\"\"\n",
    "    # Setup optimizer and scheduler\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=5e-3)  # Slightly lower LR for resume\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "    \n",
    "    # Get initial validation accuracy\n",
    "    initial_val_acc = evaluate(model, val_loader)\n",
    "    best_val_acc = initial_val_acc\n",
    "    print(f\"Initial validation accuracy: {initial_val_acc:.4f}\")\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        # Recompute centroids every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            centroids = compute_class_centroids(model, train_loader, device, num_classes)\n",
    "            print(f\"Recomputed centroids at epoch {epoch}\")\n",
    "\n",
    "        model.train()\n",
    "        running_loss, running_corr, running_total = 0, 0, 0\n",
    "\n",
    "        for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            # 1) Clean loss\n",
    "            logits_clean = model(xb)\n",
    "            loss_clean = F.cross_entropy(logits_clean, yb)\n",
    "\n",
    "            # 2) QNI-CCP perturbation in feature space\n",
    "            perturbed_features = qni_ccp_feature_perturbation_fixed(\n",
    "                model, xb, yb, centroids, epsilon_q=epsilon_q\n",
    "            )\n",
    "            q_out = torch.stack([model.q_layer(f) for f in perturbed_features])\n",
    "            logits_qni = model.classifier(q_out)\n",
    "            loss_qni = F.cross_entropy(logits_qni, yb)\n",
    "\n",
    "            # 3) FGSM adversarial loss\n",
    "            xb_fgsm = fgsm_attack(model, xb, yb, eps_fgsm=epsilon_fgsm)\n",
    "            logits_fgsm = model(xb_fgsm)\n",
    "            loss_fgsm = F.cross_entropy(logits_fgsm, yb)\n",
    "\n",
    "            # 4) PGD adversarial loss\n",
    "            xb_pgd = pgd_attack(\n",
    "                model, xb, yb,\n",
    "                pgd_eps=eps_pgd,\n",
    "                pgd_alpha=alpha_pgd,\n",
    "                pgd_iters=iters_pgd\n",
    "            )\n",
    "            logits_pgd = model(xb_pgd)\n",
    "            loss_pgd = F.cross_entropy(logits_pgd, yb)\n",
    "\n",
    "            # 5) Centroid regularization\n",
    "            current_features = torch.tanh(model.feature_extractor(xb))\n",
    "            centroid_reg = ((current_features - centroids[yb])**2).mean()\n",
    "\n",
    "            # Combine all losses with weights\n",
    "            loss = (\n",
    "                0.5 * loss_clean +    # clean\n",
    "                0.15 * loss_qni +     # QNI-CCP\n",
    "                0.1 * loss_fgsm +     # FGSM\n",
    "                0.15 * loss_pgd +     # PGD\n",
    "                0.1 * centroid_reg    # centroid reg\n",
    "            )\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            opt.step()\n",
    "\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "            running_corr += (logits_clean.argmax(1) == yb).sum().item()\n",
    "            running_total += xb.size(0)\n",
    "\n",
    "        train_loss = running_loss / running_total\n",
    "        train_acc = running_corr / running_total\n",
    "        sched.step(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        print(f\"Epoch {epoch:2d} | Train L: {train_loss:.4f} | \"\n",
    "              f\"Train A: {train_acc:.4f} | Val A: {val_acc:.4f}\")\n",
    "\n",
    "        # Save model after each epoch\n",
    "        epoch_model_path = f\"qni_ccp_adv_model_epoch_{epoch}.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'scheduler_state_dict': sched.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_acc': val_acc,\n",
    "            'best_val_acc': best_val_acc\n",
    "        }, epoch_model_path)\n",
    "        print(f\"💾 Saved model for epoch {epoch}\")\n",
    "\n",
    "        # Update best model if validation accuracy improved\n",
    "       \n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': opt.state_dict(),\n",
    "                'scheduler_state_dict': sched.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'train_acc': train_acc,\n",
    "                'val_acc': val_acc,\n",
    "                'best_val_acc': best_val_acc\n",
    "            }, \"best_qni_ccp_adv_model_resumed.pth\")\n",
    "        print(f\"🏆 New best model saved with val_acc: {val_acc:.4f}\")\n",
    "\n",
    "    return best_val_acc\n",
    "\n",
    "# ========== RESUME TRAINING EXECUTION ==========\n",
    "print(\"Resuming training...\")\n",
    "\n",
    "# Compute quantum epsilon and centroids\n",
    "epsilon_q = compute_quantum_epsilon(model, n_cnots=30, depth=6, alpha=1.0, beta=1.0)\n",
    "centroids = compute_class_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "print(f\"Quantum epsilon: {epsilon_q:.4f}\")\n",
    "print(\"Centroids computed\")\n",
    "\n",
    "# Resume training for 15 more epochs\n",
    "best_val_resumed = resume_training_with_feature_perturbation_and_adv(\n",
    "    model, train_loader, val_loader,\n",
    "    centroids, epsilon_q,\n",
    "    epsilon_fgsm=0.03,\n",
    "    eps_pgd=0.1, alpha_pgd=0.01, iters_pgd=7,\n",
    "    num_epochs=15,\n",
    "    start_epoch=11  # You can adjust this if you know the exact epoch number\n",
    ")\n",
    "\n",
    "print(f\"✅ Training resumed and completed!\")\n",
    "print(f\"Final best validation accuracy: {best_val_resumed:.4f}\")\n",
    "\n",
    "# Optional: Clean up individual epoch files if you only want to keep the best model\n",
    "import glob\n",
    "epoch_files = glob.glob(\"qni_ccp_adv_model_epoch_*.pth\")\n",
    "print(f\"Created {len(epoch_files)} epoch checkpoint files\")\n",
    "print(\"Files created:\", epoch_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
