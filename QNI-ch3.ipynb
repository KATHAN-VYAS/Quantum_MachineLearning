{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f7ad5-fd1b-478d-a0d8-5371f13909fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "added perturbation for features, earlier it was only for centroids\n",
    "\n",
    "training trained model from code - ch2, starting from 38th epoch to do adversarial training with FGSM and later with PGD\n",
    "\n",
    "model saved as: adv+QNI_model.pth \n",
    "pgd+fgsm model: adv+QNI+PGD_model.pth\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc27b8d9-94d1-418b-b075-e5ad80084252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**dataset loaded**\n",
      "Starting training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib import pyplot as plt\n",
    "import pennylane as qml\n",
    "from pennylane.qnn import TorchLayer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#for loss function \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_all(42)\n",
    "\n",
    "# ========== DEVICE ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== PARAMETERS ==========\n",
    "n_qubits = 6\n",
    "batch_size = 16\n",
    "num_classes = 25\n",
    "num_epochs = 50\n",
    "lr = 0.0005\n",
    "\n",
    "# ========== TRANSFORMS WITH DATA AUGMENTATION ==========\n",
    "# âœ… For training (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# âœ… For validation and test (no augmentation)\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# ========== DATASETS ==========\n",
    "train_dataset = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/train', transform=train_transform)\n",
    "val_dataset   = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/val', transform=eval_transform)\n",
    "test_dataset  = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/test', transform=eval_transform)\n",
    "print(\"**dataset loaded**\")\n",
    "# ========== CLASS WEIGHTS ==========\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "labels = [label for _, label in train_dataset.samples]\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(labels),\n",
    "                                     y=labels)\n",
    "class_wts = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# ========== QUANTUM CIRCUIT ==========\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "\n",
    "def quantum_circuit(inputs, weights):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(inputs[i], wires=i)\n",
    "    \n",
    "    for l in range(weights.shape[0]):\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(weights[l][i], wires=i)\n",
    "        for i in range(n_qubits - 1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "weight_shapes = {\"weights\": (6, n_qubits)}\n",
    "\n",
    "\n",
    "# ========== CNN + QNN MODEL ==========\n",
    "class FeatureReduce(nn.Module):\n",
    "    def __init__(self, final_dim, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),    # 128 -> 64\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),   # 64 -> 32\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 32 -> 16\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # 16 -> 8\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),  # â¬…ï¸ Extra block: 8 -> 4\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))                # 4Ã—4 -> 1Ã—1\n",
    "        )\n",
    "        self.fc = nn.Linear(128, final_dim)  # â¬…ï¸ Changed from 64 to 128\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class HybridQNN(nn.Module):\n",
    "    def __init__(self, n_qubits, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureReduce(final_dim=n_qubits)\n",
    "        self.q_layer = TorchLayer(quantum_circuit, weight_shapes)\n",
    "\n",
    "        # Adding 4-layer MLP after quantum layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_qubits, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.tanh(x)\n",
    "        q_out = torch.stack([self.q_layer(f) for f in x])\n",
    "        return self.classifier(q_out)\n",
    "\n",
    "# ========== TRAINING ==========\n",
    "print(\"Starting training\")\n",
    "\n",
    "# Applying gradient based pertubations of features\n",
    "def gradient_noise_on_features(model, x, y, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Compute gradient of loss w.r.t. extracted features and perturb them.\n",
    "    Returns: perturbed feature tensor [B, n_qubits]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward: extract features, apply tanh, quantum, classify\n",
    "    feats = model.feature_extractor(x)  # pre-tanh features [B, n_qubits]\n",
    "    feats_tanh = torch.tanh(feats)\n",
    "    \n",
    "    q_out = torch.stack([model.q_layer(f) for f in feats_tanh])\n",
    "    logits = model.classifier(q_out)\n",
    "    \n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get gradient w.r.t. input features\n",
    "    feats_grad = x.grad.data\n",
    "    x_pert = x + epsilon * feats_grad.sign()\n",
    "    x_pert = torch.clamp(x_pert, -1, 1)\n",
    "    \n",
    "    # Re-extract features from perturbed image\n",
    "    feats_pert = model.feature_extractor(x_pert)\n",
    "    \n",
    "    return feats_pert.detach()\n",
    "\n",
    "# â”€â”€ 2) Precompute classâ€centroids in feature space â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def compute_centroids(model, loader, device, num_classes):\n",
    "    model.eval()\n",
    "    sums = torch.zeros(num_classes, n_qubits, device=device)\n",
    "    counts = torch.zeros(num_classes, device=device)\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            feats = model.feature_extractor(x)      # preâ€tanh features\n",
    "            for c in range(num_classes):\n",
    "                mask = (y==c)\n",
    "                if mask.any():\n",
    "                    sums[c] += feats[mask].sum(0)\n",
    "                    counts[c] += mask.sum()\n",
    "    return sums / counts.unsqueeze(1)\n",
    "\n",
    "# â”€â”€ 3) QNI perturbation function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def gradient_based_noise(model, x, y, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    x: input image batch [B, C, H, W]\n",
    "    y: labels\n",
    "    \"\"\"\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    model.eval()\n",
    "\n",
    "    # Get output logits\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "\n",
    "    # Compute gradient of loss w.r.t input\n",
    "    loss.backward()\n",
    "    grad = x.grad.data  # [B, C, H, W]\n",
    "\n",
    "    # Normalize gradient and perturb input\n",
    "    grad_sign = grad.sign()\n",
    "    x_pert = x + epsilon * grad_sign\n",
    "    x_pert = torch.clamp(x_pert, -1, 1)  # Keep within normalized bounds\n",
    "\n",
    "    return x_pert.detach()\n",
    "\n",
    "# â€¦ everything above stays the same up to compute_centroids â€¦\n",
    "\n",
    "# â”€â”€ 4) Training loop with QNI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "\n",
    "# Initialize best validation accuracy\n",
    "best_val_acc = 0.0\n",
    "best_model_path = \"best_QNI_model_2.pth\"\n",
    "\n",
    "\n",
    "# helper to evaluate on a loader\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    return correct/total\n",
    "\n",
    "# initial centroids before training\n",
    "centroids = compute_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "# for epoch in range(1, 51):\n",
    "#     # every 5 epochs, recompute centroids on the *current* model:\n",
    "#     if epoch % 5 == 0:\n",
    "#         centroids = compute_centroids(model, train_loader, device, num_classes)\n",
    "    \n",
    "#     model.train()\n",
    "#     running_loss, running_correct, running_total = 0, 0, 0\n",
    "\n",
    "#     for x, y in tqdm(train_loader, desc=f\"Epoch {epoch} [train]\"):\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "\n",
    "#         ### changed\n",
    "#         # Clean path\n",
    "#         feats = model.feature_extractor(x)\n",
    "#         clean_logits = model(x)\n",
    "#         loss_clean = F.cross_entropy(clean_logits, y)\n",
    "\n",
    "#         # Perturbed path (gradient-based on features)\n",
    "#         feats_pert = gradient_noise_on_features(model, x, y, epsilon=0.1)\n",
    "#         feats_pert_t = torch.tanh(feats_pert)\n",
    "#         q_out_pert = torch.stack([model.q_layer(f) for f in feats_pert_t])\n",
    "#         pert_logits = model.classifier(q_out_pert)\n",
    "#         loss_pert = F.cross_entropy(pert_logits, y)\n",
    "\n",
    "#         # Joint loss\n",
    "#         loss = 0.8 * loss_clean + 0.2 * loss_pert\n",
    "#         opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "\n",
    "\n",
    "#         # track\n",
    "#         running_loss   += loss.item() * x.size(0)\n",
    "#         running_correct += (clean_logits.argmax(1) == y).sum().item()\n",
    "#         running_total   += y.size(0)\n",
    "\n",
    "#     # step scheduler on *average* training loss\n",
    "#     avg_train_loss = running_loss / running_total\n",
    "#     sched.step(avg_train_loss)\n",
    "\n",
    "#     train_acc = running_correct / running_total\n",
    "#     val_acc   = evaluate(model, val_loader)\n",
    "#     print(f\"\\nEpoch {epoch:2d} â€” train loss: {avg_train_loss:.4f}, \"\n",
    "#       f\"train acc: {train_acc:.4f}, val acc: {val_acc:.4f}\")\n",
    "    \n",
    "#     # Save best model\n",
    "#     if val_acc > best_val_acc:\n",
    "#         best_val_acc = val_acc\n",
    "#         torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(), \n",
    "#             'optimizer_state_dict': opt.state_dict(),\n",
    "#             'val_accuracy': val_acc\n",
    "#         }, best_model_path)F\n",
    "#         print(f\"âœ… Best model saved at epoch {epoch} with val_acc: {val_acc:.4f}\\n\")\n",
    "#     else:\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d0c1f5-8b96-4ab0-8f09-00d4f4da7853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded. Resuming from epoch 37 with best val_acc = 0.9697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [16:20<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37 â€” train loss: 0.4874, train acc: 0.9596, val acc: 0.9621\n",
      "âœ… Best adversarial model saved at epoch 37 with val_acc: 0.9621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [16:30<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38 â€” train loss: 0.3516, train acc: 0.9630, val acc: 0.9502\n",
      "âœ… Best adversarial model saved at epoch 38 with val_acc: 0.9502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [15:41<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39 â€” train loss: 0.3089, train acc: 0.9646, val acc: 0.9599\n",
      "âœ… Best adversarial model saved at epoch 39 with val_acc: 0.9599\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [15:48<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40 â€” train loss: 0.2789, train acc: 0.9663, val acc: 0.9610\n",
      "âœ… Best adversarial model saved at epoch 40 with val_acc: 0.9610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [15:53<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41 â€” train loss: 0.2625, train acc: 0.9662, val acc: 0.9556\n",
      "âœ… Best adversarial model saved at epoch 41 with val_acc: 0.9556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [16:03<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42 â€” train loss: 0.2439, train acc: 0.9655, val acc: 0.9653\n",
      "âœ… Best adversarial model saved at epoch 42 with val_acc: 0.9653\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [15:39<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43 â€” train loss: 0.2266, train acc: 0.9672, val acc: 0.9621\n",
      "âœ… Best adversarial model saved at epoch 43 with val_acc: 0.9621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [16:10<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44 â€” train loss: 0.2124, train acc: 0.9688, val acc: 0.9642\n",
      "âœ… Best adversarial model saved at epoch 44 with val_acc: 0.9642\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [15:44<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45 â€” train loss: 0.1978, train acc: 0.9681, val acc: 0.9686\n",
      "âœ… Best adversarial model saved at epoch 45 with val_acc: 0.9686\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 [adv-train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [16:20<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46 â€” train loss: 0.1930, train acc: 0.9674, val acc: 0.9664\n",
      "âœ… Best adversarial model saved at epoch 46 with val_acc: 0.9664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### for adversarial training\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load previous model\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"best_QNI_model_2.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "best_val_acc = checkpoint['val_accuracy']\n",
    "print(f\"âœ… Model loaded. Resuming from epoch {start_epoch} with best val_acc = {best_val_acc:.4f}\")\n",
    "\n",
    "# FGSM adversarial example generator\n",
    "def fgsm_attack_inputs(model, x, y, epsilon=0.1):\n",
    "    x_adv = x.clone().detach().requires_grad_(True).to(device)\n",
    "    y = y.to(device)\n",
    "    model.eval()\n",
    "    logits = model(x_adv)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "    return torch.clamp(x_adv, -1.0, 1.0).detach()\n",
    "\n",
    "# Resume training for 10 more epochs with adversarial examples\n",
    "for epoch in range(start_epoch, start_epoch + 10):\n",
    "    if epoch % 5 == 0:\n",
    "        centroids = compute_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "    model.train()\n",
    "    running_loss, running_correct, running_total = 0, 0, 0\n",
    "\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch} [adv-train]\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Clean input loss\n",
    "        clean_logits = model(x)\n",
    "        loss_clean = F.cross_entropy(clean_logits, y)\n",
    "\n",
    "        # Adversarial input loss (FGSM)\n",
    "        x_adv = fgsm_attack_inputs(model, x, y, epsilon=0.1)\n",
    "        adv_logits = model(x_adv)\n",
    "        loss_adv = F.cross_entropy(adv_logits, y)\n",
    "\n",
    "        # Combine losses\n",
    "        loss = 0.7 * loss_clean + 0.3 * loss_adv\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # Track\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        running_correct += (clean_logits.argmax(1) == y).sum().item()\n",
    "        running_total += y.size(0)\n",
    "\n",
    "    avg_train_loss = running_loss / running_total\n",
    "    sched.step(avg_train_loss)\n",
    "\n",
    "    train_acc = running_correct / running_total\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "    print(f\"\\nEpoch {epoch:2d} â€” train loss: {avg_train_loss:.4f}, \"\n",
    "          f\"train acc: {train_acc:.4f}, val acc: {val_acc:.4f}\")\n",
    "\n",
    "   # Save only the best model during adversarial training\n",
    "   \n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'val_accuracy': val_acc\n",
    "        }, \"adv+QNI_model.pth\")\n",
    "    print(f\"âœ… Best adversarial model saved at epoch {epoch} with val_acc: {val_acc:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4628ff4d-88a9-4577-accb-7e62e03af116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Resuming from FGSM-trained model | Epoch 47, Best Val Acc: 0.9664\n"
     ]
    }
   ],
   "source": [
    "# example: adv+QNI_model.pth (from FGSM training)\n",
    "checkpoint = torch.load(\"adv+QNI_model.pth\", map_location=device)\n",
    "\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "best_val_acc = checkpoint['val_accuracy']\n",
    "print(f\"âœ… Resuming from FGSM-trained model | Epoch {start_epoch}, Best Val Acc: {best_val_acc:.4f}\")\n",
    "\n",
    "def pgd_attack_inputs(model, x, y, eps=0.1, alpha=0.01, iters=7):\n",
    "    x_adv = x.clone().detach().to(device)\n",
    "    x_adv = x_adv + torch.empty_like(x_adv).uniform_(-eps, eps)\n",
    "    x_adv = torch.clamp(x_adv, -1.0, 1.0).detach()\n",
    "\n",
    "    for _ in range(iters):\n",
    "        x_adv.requires_grad_(True)\n",
    "        logits = model(x_adv)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
    "        delta = torch.clamp(x_adv - x, -eps, eps)\n",
    "        x_adv = torch.clamp(x + delta, -1.0, 1.0).detach()\n",
    "    return x_adv\n",
    "\n",
    "# Start PGD training from epoch 47\n",
    "# for epoch in range(start_epoch, start_epoch + 10):  # you can increase 10 to more if needed\n",
    "#     if epoch % 5 == 0:\n",
    "#         centroids = compute_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "#     model.train()\n",
    "#     running_loss, running_correct, running_total = 0, 0, 0\n",
    "\n",
    "#     for x, y in tqdm(train_loader, desc=f\"Epoch {epoch} [PGD-adv-train]\"):\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "\n",
    "#         # Clean input loss\n",
    "#         clean_logits = model(x)\n",
    "#         loss_clean = F.cross_entropy(clean_logits, y)\n",
    "\n",
    "#         # PGD adversarial input\n",
    "#         x_pgd = pgd_attack_inputs(model, x, y, eps=0.1, alpha=0.01, iters=7)\n",
    "#         logits_pgd = model(x_pgd)\n",
    "#         loss_pgd = F.cross_entropy(logits_pgd, y)\n",
    "\n",
    "#         # Combine losses\n",
    "#         loss = 0.6 * loss_clean + 0.4 * loss_pgd\n",
    "\n",
    "#         opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "\n",
    "#         running_loss += loss.item() * x.size(0)\n",
    "#         running_correct += (clean_logits.argmax(1) == y).sum().item()\n",
    "#         running_total += x.size(0)\n",
    "\n",
    "#     avg_train_loss = running_loss / running_total\n",
    "#     train_acc = running_correct / running_total\n",
    "#     sched.step(avg_train_loss)\n",
    "\n",
    "#     val_acc = evaluate(model, val_loader)\n",
    "\n",
    "#     print(f\"\\nEpoch {epoch:2d} â€” train loss: {avg_train_loss:.4f}, \"\n",
    "#           f\"train acc: {train_acc:.4f}, val acc: {val_acc:.4f}\")\n",
    "\n",
    "    \n",
    "#     best_val_acc = val_acc\n",
    "#     torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': opt.state_dict(),\n",
    "#             'val_accuracy': val_acc\n",
    "#         }, \"adv+QNI+PGD_model.pth\")\n",
    "#     print(f\"âœ… PGD adversarial model saved at epoch {epoch} with val_acc: {val_acc:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc9418f-3a11-4e03-b119-7f890274dbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Resuming training from epoch 62, best val acc so far: 0.9664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e4999b57ae43b58a59ef3d1379d8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 62 [Continue PGD Adv Train]:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Epoch 62 | Train Loss: 0.4012 | Train Acc: 0.9021 | Val Acc: 0.9697\n",
      "ðŸ’¾ Model saved after epoch 62 with val acc: 0.9697\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889a813f589a487e89e70af07186411c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 63 [Continue PGD Adv Train]:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Epoch 63 | Train Loss: 0.3982 | Train Acc: 0.9000 | Val Acc: 0.9198\n",
      "ðŸ’¾ Model saved after epoch 63 with val acc: 0.9198\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0b435b9d4a4204b66c1b713ecf9f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 64 [Continue PGD Adv Train]:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m loss_clean \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits_clean, y)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# PGD adversarial input\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m x_pgd \u001b[38;5;241m=\u001b[39m \u001b[43mpgd_attack_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m logits_pgd \u001b[38;5;241m=\u001b[39m model(x_pgd)\n\u001b[1;32m     36\u001b[0m loss_pgd \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits_pgd, y)\n",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mpgd_attack_inputs\u001b[0;34m(model, x, y, eps, alpha, iters)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iters):\n\u001b[1;32m     20\u001b[0m     x_adv\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 21\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_adv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y)\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 179\u001b[0m, in \u001b[0;36mHybridQNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(x)\n\u001b[1;32m    178\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(x)\n\u001b[0;32m--> 179\u001b[0m q_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_layer(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(q_out)\n",
      "Cell \u001b[0;32mIn[2], line 179\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    177\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(x)\n\u001b[1;32m    178\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(x)\n\u001b[0;32m--> 179\u001b[0m q_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(q_out)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/qnn/torch.py:404\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(inputs, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/qnn/torch.py:430\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    426\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m    429\u001b[0m }\n\u001b[0;32m--> 430\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/qnode.py:882\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/qnode.py:855\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_program\u001b[38;5;241m.\u001b[39mset_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m--> 855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    866\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/execution.py:244\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, transform_program, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, mcm_config, config, inner_transform)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_program\u001b[38;5;241m.\u001b[39mis_informative:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(tapes)\n\u001b[0;32m--> 244\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(results)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/run.py:286\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    282\u001b[0m no_interface_boundary_required \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    283\u001b[0m     config\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;241m==\u001b[39m Interface\u001b[38;5;241m.\u001b[39mNUMPY \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mgradient_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_interface_boundary_required:\n\u001b[0;32m--> 286\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43minner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# TODO: Prune once support for tf-autograph is dropped\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/run.py:251\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes)\u001b[0m\n\u001b[1;32m    248\u001b[0m transformed_tapes, transform_post_processing \u001b[38;5;241m=\u001b[39m inner_transform(tapes)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[0;32m--> 251\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     results \u001b[38;5;241m=\u001b[39m ()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:28\u001b[0m, in \u001b[0;36m_track_execute.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(untracked_execute)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, execution_config\u001b[38;5;241m=\u001b[39mDefaultExecutionConfig):\n\u001b[0;32m---> 28\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43muntracked_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(circuits, QuantumScript):\n\u001b[1;32m     30\u001b[0m         batch \u001b[38;5;241m=\u001b[39m (circuits,)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/modifiers/single_tape_support.py:30\u001b[0m, in \u001b[0;36m_make_execute.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     28\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[0;32m---> 30\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m results\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/logging/decorators.py:61\u001b[0m, in \u001b[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     s_caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::L\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     55\u001b[0m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetouterframes(inspect\u001b[38;5;241m.\u001b[39mcurrentframe(), \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m     lgr\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_debug_log_kwargs,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:719\u001b[0m, in \u001b[0;36mDefaultQubit.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    709\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    710\u001b[0m         (\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJitting executions with many circuits may have substantial classical overhead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m     )\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_simulate_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebugger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_debugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minterface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprng_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmcm_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostselect_mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostselect_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprng_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m vanilla_circuits \u001b[38;5;241m=\u001b[39m convert_to_numpy_parameters(circuits)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    736\u001b[0m seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m31\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:720\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    709\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    710\u001b[0m         (\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJitting executions with many circuits may have substantial classical overhead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m     )\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 720\u001b[0m         \u001b[43m_simulate_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebugger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_debugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minterface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprng_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmcm_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostselect_mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostselect_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c, _key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(circuits, prng_keys)\n\u001b[1;32m    733\u001b[0m     )\n\u001b[1;32m    735\u001b[0m vanilla_circuits \u001b[38;5;241m=\u001b[39m convert_to_numpy_parameters(circuits)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    736\u001b[0m seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m31\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:1053\u001b[0m, in \u001b[0;36m_simulate_wrapper\u001b[0;34m(circuit, kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_simulate_wrapper\u001b[39m(circuit, kwargs):\n\u001b[0;32m-> 1053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/logging/decorators.py:61\u001b[0m, in \u001b[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     s_caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::L\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     55\u001b[0m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetouterframes(inspect\u001b[38;5;241m.\u001b[39mcurrentframe(), \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m     lgr\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_debug_log_kwargs,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/simulate.py:357\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m(circuit, debugger, state_cache, **execution_kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(results)\n\u001b[1;32m    356\u001b[0m ops_key, meas_key \u001b[38;5;241m=\u001b[39m jax_random_split(prng_key)\n\u001b[0;32m--> 357\u001b[0m state, is_state_batched \u001b[38;5;241m=\u001b[39m \u001b[43mget_final_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebugger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mops_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexecution_kwargs\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     state_cache[circuit\u001b[38;5;241m.\u001b[39mhash] \u001b[38;5;241m=\u001b[39m state\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/logging/decorators.py:61\u001b[0m, in \u001b[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     s_caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::L\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     55\u001b[0m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetouterframes(inspect\u001b[38;5;241m.\u001b[39mcurrentframe(), \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m     lgr\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_debug_log_kwargs,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/simulate.py:190\u001b[0m, in \u001b[0;36mget_final_state\u001b[0;34m(circuit, debugger, **execution_kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, MidMeasureMP):\n\u001b[1;32m    189\u001b[0m     prng_key, key \u001b[38;5;241m=\u001b[39m jax_random_split(prng_key)\n\u001b[0;32m--> 190\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mapply_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_state_batched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexecution_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Handle postselection on mid-circuit measurements\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, qml\u001b[38;5;241m.\u001b[39mProjector):\n",
      "File \u001b[0;32m/usr/lib/python3.10/functools.py:889\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    887\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/apply_operation.py:232\u001b[0m, in \u001b[0;36mapply_operation\u001b[0;34m(op, state, is_state_batched, debugger, **_)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_operation\u001b[39m(\n\u001b[1;32m    168\u001b[0m     op: qml\u001b[38;5;241m.\u001b[39moperation\u001b[38;5;241m.\u001b[39mOperator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_,\n\u001b[1;32m    173\u001b[0m ):\n\u001b[1;32m    174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply and operator to a given state.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_operation_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/apply_operation.py:258\u001b[0m, in \u001b[0;36m_apply_operation_default\u001b[0;34m(op, state, is_state_batched, debugger)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_operation_csr_matrix(op, state, is_state_batched\u001b[38;5;241m=\u001b[39mis_state_batched)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mlen\u001b[39m(op\u001b[38;5;241m.\u001b[39mwires) \u001b[38;5;241m<\u001b[39m EINSUM_OP_WIRECOUNT_PERF_THRESHOLD\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m math\u001b[38;5;241m.\u001b[39mndim(state) \u001b[38;5;241m<\u001b[39m EINSUM_STATE_WIRECOUNT_PERF_THRESHOLD\n\u001b[1;32m    257\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (op\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mand\u001b[39;00m is_state_batched):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_operation_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_state_batched\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m apply_operation_tensordot(op, state, is_state_batched\u001b[38;5;241m=\u001b[39mis_state_batched)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/apply_operation.py:101\u001b[0m, in \u001b[0;36mapply_operation_einsum\u001b[0;34m(op, state, is_state_batched)\u001b[0m\n\u001b[1;32m     99\u001b[0m new_mat_shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m (num_indices \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    100\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnum_indices\n\u001b[0;32m--> 101\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Add broadcasting dimension to shape\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     new_mat_shape \u001b[38;5;241m=\u001b[39m [batch_size] \u001b[38;5;241m+\u001b[39m new_mat_shape\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/math/matrix_manipulation.py:341\u001b[0m, in \u001b[0;36mget_batch_size\u001b[0;34m(tensor, expected_shape, expected_size)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     size \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msize(tensor)\n\u001b[0;32m--> 341\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m(tensor)\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(expected_shape) \u001b[38;5;129;01mor\u001b[39;00m size \u001b[38;5;241m>\u001b[39m expected_size:\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m expected_size\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/math/__init__.py:143\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnumpy_mimic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/math/__init__.py:129\u001b[0m, in \u001b[0;36mNumpyMimic.__getattribute__\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Subclass of the Autoray NumpyMimic class in order to support\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mthe NumPy fft submodule\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# pylint: disable=too-few-public-methods\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m numpy_fft\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === Load the PGD + QNI checkpoint for continuing training on PGD ===\n",
    "checkpoint_path = \"adv+QNI+PGD_model.pth\"\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "best_val_acc = checkpoint['val_accuracy']\n",
    "\n",
    "print(f\"ðŸ”„ Resuming training from epoch {start_epoch}, best val acc so far: {best_val_acc:.4f}\")\n",
    "\n",
    "# === Continue training ===\n",
    "for epoch in range(start_epoch, start_epoch + 10):  # â¬…ï¸ change to how many more epochs you want\n",
    "    if epoch % 5 == 0:\n",
    "        centroids = compute_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "    model.train()\n",
    "    running_loss, running_correct, running_total = 0, 0, 0\n",
    "\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch} [Continue PGD Adv Train]\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Clean loss\n",
    "        logits_clean = model(x)\n",
    "        loss_clean = F.cross_entropy(logits_clean, y)\n",
    "\n",
    "        # PGD adversarial input\n",
    "        x_pgd = pgd_attack_inputs(model, x, y, eps=0.1, alpha=0.01, iters=7)\n",
    "        logits_pgd = model(x_pgd)\n",
    "        loss_pgd = F.cross_entropy(logits_pgd, y)\n",
    "\n",
    "        # Combined loss\n",
    "        loss = 0.6 * loss_clean + 0.4 * loss_pgd\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        running_correct += (logits_clean.argmax(1) == y).sum().item()\n",
    "        running_total += x.size(0)\n",
    "\n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc = running_correct / running_total\n",
    "    sched.step(train_loss)\n",
    "\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"ðŸ“Š Epoch {epoch:2d} | Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best or every checkpoint\n",
    "    best_val_acc = max(best_val_acc, val_acc)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': opt.state_dict(),\n",
    "        'val_accuracy': best_val_acc\n",
    "    }, \"adv+QNI+PGD_model.pth\")\n",
    "    print(f\"ðŸ’¾ Model saved after epoch {epoch} with val acc: {val_acc:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15bc4492-29c8-4ac7-9104-33d61774282b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'adv+QNI_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## to evaluate the saved model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# === Evaluate saved model ===\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m HybridQNN(n_qubits, num_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madv+QNI_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'adv+QNI_model.pth'"
     ]
    }
   ],
   "source": [
    "## to evaluate the saved model\n",
    "\n",
    "# === Evaluate saved model ===\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "checkpoint = torch.load(\"adv+QNI_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_s tate_dict'])\n",
    "model.eval()\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "val_acc = evaluate(model, val_loader)\n",
    "test_acc = evaluate(model, test_loader)\n",
    "\n",
    "print(f\"âœ… Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"âœ… Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13cec6-9124-4401-987b-fd1c0e4bfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "\n",
    "# Initialize the model\n",
    "model = HybridQNN(n_qubits=n_qubits, num_classes=num_classes).to(device)\n",
    "\n",
    "# âœ… Load only the model weights from the saved checkpoint\n",
    "checkpoint = torch.load(\"best_QNI_model_2.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  # â¬…ï¸ fix\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Get class names from the test dataset\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e593f34-746b-4998-9d87-d575d774a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Clean Test Accuracy: 95.63%\n",
      "FGSM Adversarial Accuracy: 83.14%\n",
      "PGD Adversarial Accuracy: 23.20%\n"
     ]
    }
   ],
   "source": [
    "## performing FGSM attack\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ===== FGSM Attack =====\n",
    "def fgsm_attack(model, x, y, epsilon=0.1, device='cuda'):\n",
    "    model.eval()\n",
    "    x_adv = x.clone().detach().to(device).requires_grad_(True)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logits = model(x_adv)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "    x_adv = torch.clamp(x_adv, min=-1.0, max=1.0)\n",
    "    return x_adv.detach()\n",
    "\n",
    "# ===== PGD Attack =====\n",
    "def pgd_attack(model, x, y, eps=0.1, alpha=0.02, iters=10, device='cuda'):\n",
    "    model.eval()\n",
    "    x_orig = x.clone().detach().to(device)\n",
    "    x_adv  = x_orig + torch.empty_like(x_orig).uniform_(-eps, eps)\n",
    "    x_adv  = torch.clamp(x_adv, -1.0, 1.0).detach()\n",
    "\n",
    "    y = y.to(device)\n",
    "    for _ in range(iters):\n",
    "        x_adv.requires_grad_(True)\n",
    "        logits = model(x_adv)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
    "        delta = torch.clamp(x_adv - x_orig, min=-eps, max=eps)\n",
    "        x_adv = torch.clamp(x_orig + delta, -1.0, 1.0).detach()\n",
    "    return x_adv\n",
    "\n",
    "# ===== Evaluate Attack =====\n",
    "def test_adversarial(model, loader, attack_fn, attack_name, **attack_kwargs):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack_fn(model, x, y, **attack_kwargs)\n",
    "        logits = model(x_adv)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"{attack_name} Adversarial Accuracy: {acc:.2f}%\")\n",
    "\n",
    "# ===== Load Model from best_QNI_model_2.pth =====\n",
    "model = HybridQNN(n_qubits=n_qubits, num_classes=num_classes).to(device)\n",
    "checkpoint = torch.load(\"adv+QNI_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# ===== Run Evaluations =====\n",
    "# Clean accuracy\n",
    "clean_acc = evaluate(model, test_loader)\n",
    "print(f\"\\nâœ… Clean Test Accuracy: {clean_acc*100:.2f}%\")\n",
    "\n",
    "# FGSM attack\n",
    "test_adversarial(\n",
    "    model, test_loader,\n",
    "    attack_fn=fgsm_attack,\n",
    "    attack_name=\"FGSM\",\n",
    "    epsilon=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# PGD attack\n",
    "test_adversarial(\n",
    "    model, test_loader,\n",
    "    attack_fn=pgd_attack,\n",
    "    attack_name=\"PGD\",\n",
    "    eps=0.1,\n",
    "    alpha=0.02,\n",
    "    iters=10,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc3c09-3d1f-4b42-9f2c-e465ebd5ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== claude FGSM, PGD Attack code =====\n",
    "def fgsm_attack(model, x, y, epsilon=0.1, device='cuda'):\n",
    "    \"\"\"\n",
    "    Fast Gradient Sign Method (FGSM) attack\n",
    "    \n",
    "    Args:\n",
    "        model: The target model\n",
    "        x: Input tensor\n",
    "        y: True labels\n",
    "        epsilon: Attack strength\n",
    "        device: Device to run on\n",
    "    \n",
    "    Returns:\n",
    "        Adversarial examples\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x_adv = x.clone().detach().to(device).requires_grad_(True)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(x_adv)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Generate adversarial example\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "    x_adv = torch.clamp(x_adv, min=-1.0, max=1.0)\n",
    "    \n",
    "    return x_adv.detach()\n",
    "\n",
    "\n",
    "# ===== IMPROVED PGD Attack =====\n",
    "def pgd_attack(model, x, y, eps=0.1, alpha=0.02, iters=10, device='cuda', random_start=True):\n",
    "    \"\"\"\n",
    "    Projected Gradient Descent (PGD) attack\n",
    "    \n",
    "    Args:\n",
    "        model: The target model\n",
    "        x: Input tensor\n",
    "        y: True labels\n",
    "        eps: Maximum perturbation (Lâˆž norm)\n",
    "        alpha: Step size\n",
    "        iters: Number of iterations\n",
    "        device: Device to run on\n",
    "        random_start: Whether to start from random point in eps-ball\n",
    "    \n",
    "    Returns:\n",
    "        Adversarial examples\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x_orig = x.clone().detach().to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # Initialize adversarial example\n",
    "    if random_start:\n",
    "        x_adv = x_orig + torch.empty_like(x_orig).uniform_(-eps, eps)\n",
    "        x_adv = torch.clamp(x_adv, -1.0, 1.0).detach()\n",
    "    else:\n",
    "        x_adv = x_orig.clone().detach()\n",
    "    \n",
    "    # PGD iterations\n",
    "    for i in range(iters):\n",
    "        x_adv.requires_grad_(True)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(x_adv)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update adversarial example\n",
    "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
    "        \n",
    "        # Project back to eps-ball around original input\n",
    "        delta = torch.clamp(x_adv - x_orig, min=-eps, max=eps)\n",
    "        x_adv = torch.clamp(x_orig + delta, -1.0, 1.0).detach()\n",
    "    \n",
    "    return x_adv\n",
    "\n",
    "\n",
    "# ===== ADDITIONAL ATTACK METHODS =====\n",
    "\n",
    "def c_w_attack(model, x, y, c=1.0, kappa=0, max_iter=1000, learning_rate=0.01, device='cuda'):\n",
    "    \"\"\"\n",
    "    Carlini & Wagner (C&W) L2 attack\n",
    "    \n",
    "    Args:\n",
    "        model: The target model\n",
    "        x: Input tensor\n",
    "        y: True labels\n",
    "        c: Confidence parameter\n",
    "        kappa: Confidence margin\n",
    "        max_iter: Maximum iterations\n",
    "        learning_rate: Learning rate for optimization\n",
    "        device: Device to run on\n",
    "    \n",
    "    Returns:\n",
    "        Adversarial examples\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x_orig = x.clone().detach().to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # Initialize perturbation parameter\n",
    "    w = torch.zeros_like(x_orig, requires_grad=True, device=device)\n",
    "    optimizer = torch.optim.Adam([w], lr=learning_rate)\n",
    "    \n",
    "    best_adv = x_orig.clone()\n",
    "    best_l2 = float('inf')\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        # Generate adversarial example using tanh transformation\n",
    "        x_adv = 0.5 * (torch.tanh(w) + 1.0)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(x_adv)\n",
    "        \n",
    "        # C&W loss function\n",
    "        # f(x) = max(max{Z_i: i != t} - Z_t, -kappa)\n",
    "        real_logits = logits.gather(1, y.unsqueeze(1)).squeeze(1)\n",
    "        other_logits = logits.clone()\n",
    "        other_logits.scatter_(1, y.unsqueeze(1), -float('inf'))\n",
    "        max_other_logits = other_logits.max(1)[0]\n",
    "        \n",
    "        f_loss = torch.clamp(max_other_logits - real_logits + kappa, min=0)\n",
    "        \n",
    "        # L2 distance\n",
    "        l2_loss = torch.norm(x_adv - x_orig, p=2, dim=(1, 2, 3))\n",
    "        \n",
    "        # Total loss\n",
    "        loss = l2_loss + c * f_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update best adversarial example\n",
    "        for j in range(x_orig.size(0)):\n",
    "            if f_loss[j] < 1e-4 and l2_loss[j] < best_l2:\n",
    "                best_l2 = l2_loss[j].item()\n",
    "                best_adv[j] = x_adv[j].detach()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: L2 loss = {l2_loss.mean().item():.4f}, \"\n",
    "                  f\"F loss = {f_loss.mean().item():.4f}\")\n",
    "    \n",
    "    return best_adv\n",
    "\n",
    "\n",
    "def evaluate_robustness(model, test_loader, attacks, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate model robustness against multiple attacks\n",
    "    \n",
    "    Args:\n",
    "        model: Model to evaluate\n",
    "        test_loader: Test data loader\n",
    "        attacks: Dictionary of attack functions\n",
    "        device: Device to run on\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of accuracy results\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    \n",
    "    # Clean accuracy\n",
    "    clean_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(1)\n",
    "            clean_correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    \n",
    "    results['clean'] = clean_correct / total\n",
    "    print(f\"Clean accuracy: {results['clean']:.4f}\")\n",
    "    \n",
    "    # Adversarial accuracy for each attack\n",
    "    for attack_name, attack_func in attacks.items():\n",
    "        adv_correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Generate adversarial examples\n",
    "            x_adv = attack_func(model, x, y, device=device)\n",
    "            \n",
    "            # Evaluate on adversarial examples\n",
    "            with torch.no_grad():\n",
    "                logits = model(x_adv)\n",
    "                pred = logits.argmax(1)\n",
    "                adv_correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        \n",
    "        results[attack_name] = adv_correct / total\n",
    "        print(f\"{attack_name} accuracy: {results[attack_name]:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ===== USAGE EXAMPLE =====\n",
    "def test_attacks():\n",
    "    \"\"\"\n",
    "    Example usage of the attack functions\n",
    "    \"\"\"\n",
    "    # Define attacks\n",
    "    attacks = {\n",
    "        'fgsm_0.1': lambda model, x, y, device: fgsm_attack(model, x, y, epsilon=0.1, device=device),\n",
    "        'fgsm_0.2': lambda model, x, y, device: fgsm_attack(model, x, y, epsilon=0.2, device=device),\n",
    "        'pgd_0.1': lambda model, x, y, device: pgd_attack(model, x, y, eps=0.1, alpha=0.02, iters=10, device=device),\n",
    "        'pgd_0.2': lambda model, x, y, device: pgd_attack(model, x, y, eps=0.2, alpha=0.04, iters=20, device=device),\n",
    "    }\n",
    "    \n",
    "    # Evaluate robustness (assuming model and test_loader are defined)\n",
    "    # results = evaluate_robustness(model, test_loader, attacks, device='cuda')\n",
    "    \n",
    "    return attacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
