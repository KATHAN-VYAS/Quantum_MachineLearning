{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f7ad5-fd1b-478d-a0d8-5371f13909fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "added perturbation for features, earlier it was only for centroids\n",
    "formula for epsilon\n",
    "\n",
    "contains base model code, additional model training code, classification report, after-attack accuracy\n",
    "\n",
    "model saved as: best_adv_qni_model.pth\n",
    "\n",
    "**added fgsm after some ephoch of training\n",
    "\n",
    "QNI had some problems in this code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc27b8d9-94d1-418b-b075-e5ad80084252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**dataset loaded**\n",
      "Starting training\n",
      "✅ Loaded pretrained model with QNI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594373c07a7545188b8932420f62e295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train L: 0.5992 | Train A: 0.8370 | Val A: 0.8072\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40a1f8ad6cf4ca784b446001a19f27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train L: 0.5365 | Train A: 0.8666 | Val A: 0.8397\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0be155247cd45a7a839414731447fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train L: 0.4860 | Train A: 0.8792 | Val A: 0.8917\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0e2e87e96347dbbb7a9d7a814887a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train L: 0.4540 | Train A: 0.8988 | Val A: 0.8635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a790843fee7454bbc6bf425dd20506c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train L: 0.3688 | Train A: 0.9229 | Val A: 0.9003\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6b6a1efc4b4ec6abfcb30f95ae6ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train L: 0.3212 | Train A: 0.9347 | Val A: 0.9372\n",
      "💾 Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5ec54fd35e4b6fb2f2f796d7cdaf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train L: 0.3149 | Train A: 0.9389 | Val A: 0.9242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39f9d5eae7b418184bae073dc385e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train L: 0.3047 | Train A: 0.9383 | Val A: 0.9285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea85f32b854545adb6139e3d59d368ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 347\u001b[0m\n\u001b[1;32m    343\u001b[0m loss_qni   \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits_qni, yb)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# — PGD loss ————————————————\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m xb_pgd \u001b[38;5;241m=\u001b[39m \u001b[43mpgd_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m logits_pgd \u001b[38;5;241m=\u001b[39m model(xb_pgd)\n\u001b[1;32m    349\u001b[0m loss_pgd   \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits_pgd, yb)\n",
      "Cell \u001b[0;32mIn[2], line 124\u001b[0m, in \u001b[0;36mpgd_attack\u001b[0;34m(model, x, y, eps, alpha, iters)\u001b[0m\n\u001b[1;32m    122\u001b[0m x_adv \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iters):\n\u001b[0;32m--> 124\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_adv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y)\n\u001b[1;32m    126\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 204\u001b[0m, in \u001b[0;36mHybridQNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(x)\n\u001b[1;32m    203\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(x)\n\u001b[0;32m--> 204\u001b[0m q_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_layer(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(q_out)\n",
      "Cell \u001b[0;32mIn[2], line 204\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    202\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(x)\n\u001b[1;32m    203\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(x)\n\u001b[0;32m--> 204\u001b[0m q_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(q_out)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/qnn/torch.py:404\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(inputs, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/qnn/torch.py:430\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    426\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m    429\u001b[0m }\n\u001b[0;32m--> 430\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/qnode.py:882\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/qnode.py:855\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_program\u001b[38;5;241m.\u001b[39mset_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m--> 855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    866\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/execution.py:244\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, transform_program, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, mcm_config, config, inner_transform)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_program\u001b[38;5;241m.\u001b[39mis_informative:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(tapes)\n\u001b[0;32m--> 244\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(results)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/run.py:286\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    282\u001b[0m no_interface_boundary_required \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    283\u001b[0m     config\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;241m==\u001b[39m Interface\u001b[38;5;241m.\u001b[39mNUMPY \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mgradient_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_interface_boundary_required:\n\u001b[0;32m--> 286\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43minner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# TODO: Prune once support for tf-autograph is dropped\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/workflow/run.py:251\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes)\u001b[0m\n\u001b[1;32m    248\u001b[0m transformed_tapes, transform_post_processing \u001b[38;5;241m=\u001b[39m inner_transform(tapes)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[0;32m--> 251\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     results \u001b[38;5;241m=\u001b[39m ()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:28\u001b[0m, in \u001b[0;36m_track_execute.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(untracked_execute)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, execution_config\u001b[38;5;241m=\u001b[39mDefaultExecutionConfig):\n\u001b[0;32m---> 28\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43muntracked_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(circuits, QuantumScript):\n\u001b[1;32m     30\u001b[0m         batch \u001b[38;5;241m=\u001b[39m (circuits,)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/modifiers/single_tape_support.py:30\u001b[0m, in \u001b[0;36m_make_execute.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     28\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[0;32m---> 30\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m results\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/logging/decorators.py:61\u001b[0m, in \u001b[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     s_caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::L\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     55\u001b[0m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetouterframes(inspect\u001b[38;5;241m.\u001b[39mcurrentframe(), \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m     lgr\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_debug_log_kwargs,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:719\u001b[0m, in \u001b[0;36mDefaultQubit.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    709\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    710\u001b[0m         (\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJitting executions with many circuits may have substantial classical overhead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m     )\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_simulate_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebugger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_debugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minterface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprng_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmcm_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostselect_mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostselect_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprng_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m vanilla_circuits \u001b[38;5;241m=\u001b[39m convert_to_numpy_parameters(circuits)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    736\u001b[0m seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m31\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:720\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    709\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    710\u001b[0m         (\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJitting executions with many circuits may have substantial classical overhead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m     )\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 720\u001b[0m         \u001b[43m_simulate_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebugger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_debugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minterface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprng_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmcm_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostselect_mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostselect_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c, _key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(circuits, prng_keys)\n\u001b[1;32m    733\u001b[0m     )\n\u001b[1;32m    735\u001b[0m vanilla_circuits \u001b[38;5;241m=\u001b[39m convert_to_numpy_parameters(circuits)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    736\u001b[0m seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m31\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:1053\u001b[0m, in \u001b[0;36m_simulate_wrapper\u001b[0;34m(circuit, kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_simulate_wrapper\u001b[39m(circuit, kwargs):\n\u001b[0;32m-> 1053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/logging/decorators.py:61\u001b[0m, in \u001b[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     s_caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::L\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     55\u001b[0m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetouterframes(inspect\u001b[38;5;241m.\u001b[39mcurrentframe(), \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m     lgr\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_debug_log_kwargs,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/simulate.py:357\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m(circuit, debugger, state_cache, **execution_kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(results)\n\u001b[1;32m    356\u001b[0m ops_key, meas_key \u001b[38;5;241m=\u001b[39m jax_random_split(prng_key)\n\u001b[0;32m--> 357\u001b[0m state, is_state_batched \u001b[38;5;241m=\u001b[39m \u001b[43mget_final_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebugger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mops_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexecution_kwargs\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     state_cache[circuit\u001b[38;5;241m.\u001b[39mhash] \u001b[38;5;241m=\u001b[39m state\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/logging/decorators.py:61\u001b[0m, in \u001b[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     s_caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::L\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     55\u001b[0m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetouterframes(inspect\u001b[38;5;241m.\u001b[39mcurrentframe(), \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m     lgr\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_debug_log_kwargs,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/simulate.py:190\u001b[0m, in \u001b[0;36mget_final_state\u001b[0;34m(circuit, debugger, **execution_kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, MidMeasureMP):\n\u001b[1;32m    189\u001b[0m     prng_key, key \u001b[38;5;241m=\u001b[39m jax_random_split(prng_key)\n\u001b[0;32m--> 190\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mapply_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_state_batched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexecution_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Handle postselection on mid-circuit measurements\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, qml\u001b[38;5;241m.\u001b[39mProjector):\n",
      "File \u001b[0;32m/usr/lib/python3.10/functools.py:889\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    887\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/apply_operation.py:232\u001b[0m, in \u001b[0;36mapply_operation\u001b[0;34m(op, state, is_state_batched, debugger, **_)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_operation\u001b[39m(\n\u001b[1;32m    168\u001b[0m     op: qml\u001b[38;5;241m.\u001b[39moperation\u001b[38;5;241m.\u001b[39mOperator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_,\n\u001b[1;32m    173\u001b[0m ):\n\u001b[1;32m    174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply and operator to a given state.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_operation_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/apply_operation.py:258\u001b[0m, in \u001b[0;36m_apply_operation_default\u001b[0;34m(op, state, is_state_batched, debugger)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_operation_csr_matrix(op, state, is_state_batched\u001b[38;5;241m=\u001b[39mis_state_batched)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mlen\u001b[39m(op\u001b[38;5;241m.\u001b[39mwires) \u001b[38;5;241m<\u001b[39m EINSUM_OP_WIRECOUNT_PERF_THRESHOLD\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m math\u001b[38;5;241m.\u001b[39mndim(state) \u001b[38;5;241m<\u001b[39m EINSUM_STATE_WIRECOUNT_PERF_THRESHOLD\n\u001b[1;32m    257\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (op\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mand\u001b[39;00m is_state_batched):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_operation_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_state_batched\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m apply_operation_tensordot(op, state, is_state_batched\u001b[38;5;241m=\u001b[39mis_state_batched)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/devices/qubit/apply_operation.py:81\u001b[0m, in \u001b[0;36mapply_operation_einsum\u001b[0;34m(op, state, is_state_batched)\u001b[0m\n\u001b[1;32m     79\u001b[0m     mat \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mcast_like(op\u001b[38;5;241m.\u001b[39mmatrix(), state)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     mat \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0\u001b[39mj\n\u001b[1;32m     83\u001b[0m total_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(state\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m is_state_batched\n\u001b[1;32m     84\u001b[0m num_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(op\u001b[38;5;241m.\u001b[39mwires)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/operation.py:830\u001b[0m, in \u001b[0;36mOperator.matrix\u001b[0;34m(self, wire_order)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmatrix\u001b[39m(\u001b[38;5;28mself\u001b[39m, wire_order: Optional[WiresLike] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorLike:\n\u001b[1;32m    811\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Representation of the operator as a matrix in the computational basis.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m    If ``wire_order`` is provided, the numerical representation considers the position of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;124;03m        tensor_like: matrix representation\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m     canonical_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    833\u001b[0m         wire_order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwires \u001b[38;5;241m==\u001b[39m Wires(wire_order)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    838\u001b[0m         )\n\u001b[1;32m    839\u001b[0m     ):\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m canonical_matrix\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/ops/qubit/parametric_ops_single_qubit.py:256\u001b[0m, in \u001b[0;36mRY.compute_matrix\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m    254\u001b[0m c \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0\u001b[39mj) \u001b[38;5;241m*\u001b[39m c\n\u001b[1;32m    255\u001b[0m s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0\u001b[39mj) \u001b[38;5;241m*\u001b[39m s\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mstack([\u001b[43mstack_last\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, stack_last([s, c])], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/math/multi_dispatch.py:149\u001b[0m, in \u001b[0;36mmulti_dispatch.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m         dispatch_args\u001b[38;5;241m.\u001b[39mappend(args[a])\n\u001b[1;32m    148\u001b[0m interface \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlike\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 149\u001b[0m interface \u001b[38;5;241m=\u001b[39m interface \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mget_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdispatch_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlike\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m interface\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/math/interface_utils.py:126\u001b[0m, in \u001b[0;36mget_interface\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_interface_of_single_tensor(values[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 126\u001b[0m interfaces \u001b[38;5;241m=\u001b[39m {_get_interface_of_single_tensor(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(interfaces \u001b[38;5;241m-\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscipy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautograd\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# contains multiple non-autograd interfaces\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensors contain mixed types; cannot determine dispatch library\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/math/interface_utils.py:126\u001b[0m, in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_interface_of_single_tensor(values[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 126\u001b[0m interfaces \u001b[38;5;241m=\u001b[39m {\u001b[43m_get_interface_of_single_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(interfaces \u001b[38;5;241m-\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscipy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautograd\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# contains multiple non-autograd interfaces\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensors contain mixed types; cannot determine dispatch library\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/pennylane/math/interface_utils.py:171\u001b[0m, in \u001b[0;36m_get_interface_of_single_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_interface_of_single_tensor\u001b[39m(tensor):\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the name of the package that any array/tensor manipulations\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    will dispatch to. The returned strings correspond to those used for PennyLane\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    :doc:`interfaces </introduction/interfaces>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    'autograd'\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     namespace \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__module__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpennylane\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautograd\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautograd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib import pyplot as plt\n",
    "import pennylane as qml\n",
    "from pennylane.qnn import TorchLayer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#for loss function \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_all(42)\n",
    "\n",
    "# ========== DEVICE ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== PARAMETERS ==========\n",
    "n_qubits = 6\n",
    "batch_size = 16\n",
    "num_classes = 25\n",
    "num_epochs = 50\n",
    "lr = 0.0005\n",
    "\n",
    "# ========== TRANSFORMS WITH DATA AUGMENTATION ==========\n",
    "# ✅ For training (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# ✅ For validation and test (no augmentation)\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# ========== DATASETS ==========\n",
    "train_dataset = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/train', transform=train_transform)\n",
    "val_dataset   = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/val', transform=eval_transform)\n",
    "test_dataset  = ImageFolder('/home/netsec1/dataset_folder/malimg_dataset/test', transform=eval_transform)\n",
    "print(\"**dataset loaded**\")\n",
    "# ========== CLASS WEIGHTS ==========\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "labels = [label for _, label in train_dataset.samples]\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(labels),\n",
    "                                     y=labels)\n",
    "class_wts = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# ========== QUANTUM CIRCUIT ==========\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "\n",
    "def quantum_circuit(inputs, weights):\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(inputs[i], wires=i)\n",
    "    \n",
    "    for l in range(weights.shape[0]):\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(weights[l][i], wires=i)\n",
    "        for i in range(n_qubits - 1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "weight_shapes = {\"weights\": (6, n_qubits)}\n",
    "\n",
    "# pgd attack\n",
    "def pgd_attack(model, x, y, eps=0.1, alpha=0.01, iters=10):\n",
    "    \"\"\"Projected Gradient Descent attack on input x.\"\"\"\n",
    "    x_adv = x.clone().detach().requires_grad_(True)\n",
    "    for _ in range(iters):\n",
    "        logits = model(x_adv)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        # take a step in sign gradient direction\n",
    "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
    "        # project back into eps‑ball of original x\n",
    "        x_adv = torch.max(torch.min(x_adv, x + eps), x - eps).detach()\n",
    "        x_adv.requires_grad_(True)\n",
    "    return x_adv\n",
    "    \n",
    "# FGSM ATTACK FUNCTION\n",
    "def fgsm_attack(model, x, y, eps=0.03):\n",
    "    x_req = x.clone().detach().requires_grad_(True)\n",
    "    model.eval()\n",
    "    logits = model(x_req)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    x_adv = x_req + eps * x_req.grad.sign()\n",
    "    return torch.clamp(x_adv, -1, 1).detach()\n",
    "\n",
    "\n",
    "# ========== CNN + QNN MODEL ==========\n",
    "class FeatureReduce(nn.Module):\n",
    "    def __init__(self, final_dim, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),    # 128 -> 64\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),   # 64 -> 32\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 32 -> 16\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # 16 -> 8\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),  # ⬅️ Extra block: 8 -> 4\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))                # 4×4 -> 1×1\n",
    "        )\n",
    "        self.fc = nn.Linear(128, final_dim)  # ⬅️ Changed from 64 to 128\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class HybridQNN(nn.Module):\n",
    "    def __init__(self, n_qubits, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureReduce(final_dim=n_qubits)\n",
    "        self.q_layer = TorchLayer(quantum_circuit, weight_shapes)\n",
    "\n",
    "        # Adding 4-layer MLP after quantum layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_qubits, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.tanh(x)\n",
    "        q_out = torch.stack([self.q_layer(f) for f in x])\n",
    "        return self.classifier(q_out)\n",
    "\n",
    "# ========== TRAINING ==========\n",
    "print(\"Starting training\")\n",
    "\n",
    "\n",
    "def gradient_based_noise(model, x, y, epsilon=0.1):\n",
    "    x_req = x.clone().detach().requires_grad_(True)\n",
    "    model.eval()\n",
    "    logits = model(x_req)\n",
    "    loss   = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    grad_sign = x_req.grad.sign()\n",
    "    x_pert = torch.clamp(x_req + epsilon * grad_sign, -1, 1).detach()\n",
    "    return x_pert\n",
    "\n",
    "\n",
    "# Applying gradient based pertubations of features\n",
    "def qni_perturb(model, x, y, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Compute gradient of loss w.r.t. extracted features and perturb them.\n",
    "    Returns: perturbed feature tensor [B, n_qubits]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward: extract features, apply tanh, quantum, classify\n",
    "    feats = model.feature_extractor(x)  # pre-tanh features [B, n_qubits]\n",
    "    feats_tanh = torch.tanh(feats)\n",
    "    \n",
    "    q_out = torch.stack([model.q_layer(f) for f in feats_tanh])\n",
    "    logits = model.classifier(q_out)\n",
    "    \n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get gradient w.r.t. input features\n",
    "    feats_grad = x.grad.data\n",
    "    x_pert = x + epsilon * feats_grad.sign()\n",
    "    x_pert = torch.clamp(x_pert, -1, 1)\n",
    "    \n",
    "    # Re-extract features from perturbed image\n",
    "    feats_pert = model.feature_extractor(x_pert)\n",
    "    \n",
    "    return feats_pert.detach()\n",
    "\n",
    "# ── 2) Precompute class‐centroids in feature space ──────────────────────────\n",
    "def compute_centroids(model, loader, device, num_classes):\n",
    "    model.eval()\n",
    "    sums = torch.zeros(num_classes, n_qubits, device=device)\n",
    "    counts = torch.zeros(num_classes, device=device)\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            feats = model.feature_extractor(x)      # pre‐tanh features\n",
    "            for c in range(num_classes):\n",
    "                mask = (y==c)\n",
    "                if mask.any():\n",
    "                    sums[c] += feats[mask].sum(0)\n",
    "                    counts[c] += mask.sum()\n",
    "    return sums / counts.unsqueeze(1)\n",
    "\n",
    "# ── 3) QNI perturbation function ────────────────────────────────────────────\n",
    "def gradient_based_noise(model, x, y, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    x: input image batch [B, C, H, W]\n",
    "    y: labels\n",
    "    \"\"\"\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    model.eval()\n",
    "\n",
    "    # Get output logits\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "\n",
    "    # Compute gradient of loss w.r.t input\n",
    "    loss.backward()\n",
    "    grad = x.grad.data  # [B, C, H, W]\n",
    "\n",
    "    # Normalize gradient and perturb input\n",
    "    grad_sign = grad.sign()\n",
    "    x_pert = x + epsilon * grad_sign\n",
    "    x_pert = torch.clamp(x_pert, -1, 1)  # Keep within normalized bounds\n",
    "\n",
    "    return x_pert.detach()\n",
    "\n",
    "# … everything above stays the same up to compute_centroids …\n",
    "\n",
    "# ── 4) Training loop with QNI ──────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "\n",
    "# Initialize best validation accuracy\n",
    "best_val_acc = 0.0\n",
    "# best_model_path = \"best_QNI_model_2.pth\"\n",
    "\n",
    "\n",
    "# helper to evaluate on a loader\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    return correct/total\n",
    "\n",
    "# initial centroids before training\n",
    "centroids = compute_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "# LOAD SAVED MODEL (from QNI-only training)\n",
    "model.load_state_dict(torch.load(\"best_adv_qni_model.pth\"))\n",
    "print(\"✅ Loaded pretrained model with QNI\")\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    # every 5 epochs recompute centroids (optional)\n",
    "    if epoch % 5 == 0:\n",
    "        centroids = compute_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "    model.train()\n",
    "    running_loss, running_corr, running_total = 0, 0, 0\n",
    "\n",
    "    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        # — clean loss ———————————————\n",
    "        logits_clean = model(xb)\n",
    "        loss_clean  = F.cross_entropy(logits_clean, yb)\n",
    "\n",
    "        # — QNI loss ————————————————\n",
    "        # — QNI loss (image‑space gradient noise) ————————————————\n",
    "        xb_qni     = gradient_based_noise(model, xb, yb, epsilon=0.1)\n",
    "        logits_qni = model(xb_qni)\n",
    "        loss_qni   = F.cross_entropy(logits_qni, yb)\n",
    "\n",
    "\n",
    "        # — PGD loss ————————————————\n",
    "        xb_pgd = pgd_attack(model, xb, yb, eps=0.1, alpha=0.01, iters=7)\n",
    "        logits_pgd = model(xb_pgd)\n",
    "        loss_pgd   = F.cross_entropy(logits_pgd, yb)\n",
    "\n",
    "        # — centroid reg (optional) —————\n",
    "        feats = model.feature_extractor(xb)\n",
    "        c_loss = ((feats - centroids[yb])**2).mean()\n",
    "\n",
    "       # — FGSM loss (only for epoch ≥ 7) —\n",
    "        if epoch >= 7:\n",
    "            xb_fgsm = fgsm_attack(model, xb, yb, eps=0.03)\n",
    "            logits_fgsm = model(xb_fgsm)\n",
    "            loss_fgsm = F.cross_entropy(logits_fgsm, yb)\n",
    "        \n",
    "            # Combine all 4 losses\n",
    "            loss = (\n",
    "                0.4 * loss_clean +\n",
    "                0.2 * loss_qni +\n",
    "                0.2 * loss_pgd +\n",
    "                0.1 * loss_fgsm +\n",
    "                0.1 * c_loss\n",
    "            )\n",
    "        else:\n",
    "            # Before FGSM starts\n",
    "            loss = (\n",
    "                0.5 * loss_clean +\n",
    "                0.2 * loss_qni +\n",
    "                0.2 * loss_pgd +\n",
    "                0.1 * c_loss\n",
    "            )\n",
    "\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        opt.step()\n",
    "\n",
    "        running_loss   += loss.item() * xb.size(0)\n",
    "        running_corr   += (logits_clean.argmax(1)==yb).sum().item()\n",
    "        running_total  += xb.size(0)\n",
    "\n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc  = running_corr / running_total\n",
    "    sched.step(train_loss)\n",
    "\n",
    "    # — validation ——————————————\n",
    "    model.eval()\n",
    "    corr, tot = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xv, yv in val_loader:\n",
    "            xv,yv = xv.to(device), yv.to(device)\n",
    "            preds = model(xv).argmax(1)\n",
    "            corr += (preds==yv).sum().item()\n",
    "            tot  += yv.size(0)\n",
    "    val_acc = corr/tot\n",
    "\n",
    "    print(f\"Epoch {epoch:2d} | Train L: {train_loss:.4f} | Train A: {train_acc:.4f} | Val A: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_adv_qni_model.pth\")\n",
    "        print(\"💾 Saved best model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15bc4492-29c8-4ac7-9104-33d61774282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation Accuracy: 0.9372\n",
      "✅ Test Accuracy: 0.9188\n"
     ]
    }
   ],
   "source": [
    "## to evaluate the saved model\n",
    "\n",
    "# === Evaluate saved model ===\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "checkpoint = torch.load(\"best_adv_qni_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)  # ⬅️ FIXED\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "val_acc = evaluate(model, val_loader)\n",
    "test_acc = evaluate(model, test_loader)\n",
    "\n",
    "print(f\"✅ Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"✅ Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "816d10e4-6df1-4b2a-a4af-27a1775286c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Clean Test Accuracy: 91.88%\n",
      "FGSM Adversarial Accuracy: 69.61%\n",
      "PGD Adversarial Accuracy: 51.72%\n"
     ]
    }
   ],
   "source": [
    "## attacking the model with FGSM and PGD\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ===== FGSM Attack =====\n",
    "def fgsm_attack(model, x, y, epsilon=0.1, device='cuda'):\n",
    "    model.eval()\n",
    "    x_adv = x.clone().detach().to(device).requires_grad_(True)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logits = model(x_adv)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "    x_adv = torch.clamp(x_adv, min=-1.0, max=1.0)\n",
    "    return x_adv.detach()\n",
    "\n",
    "# ===== PGD Attack =====\n",
    "def pgd_attack(model, x, y, eps=0.1, alpha=0.02, iters=10, device='cuda'):\n",
    "    model.eval()\n",
    "    x_orig = x.clone().detach().to(device)\n",
    "    x_adv  = x_orig + torch.empty_like(x_orig).uniform_(-eps, eps)\n",
    "    x_adv  = torch.clamp(x_adv, -1.0, 1.0).detach()\n",
    "\n",
    "    y = y.to(device)\n",
    "    for _ in range(iters):\n",
    "        x_adv.requires_grad_(True)\n",
    "        logits = model(x_adv)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
    "        delta = torch.clamp(x_adv - x_orig, min=-eps, max=eps)\n",
    "        x_adv = torch.clamp(x_orig + delta, -1.0, 1.0).detach()\n",
    "    return x_adv\n",
    "\n",
    "# ===== Evaluate Attack =====\n",
    "def test_adversarial(model, loader, attack_fn, attack_name, **attack_kwargs):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack_fn(model, x, y, **attack_kwargs)\n",
    "        logits = model(x_adv)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"{attack_name} Adversarial Accuracy: {acc:.2f}%\")\n",
    "\n",
    "# ===== Load Model =====\n",
    "model = HybridQNN(n_qubits=n_qubits, num_classes=num_classes).to(device)\n",
    "checkpoint = torch.load(\"best_adv_qni_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# ===== Run Evaluations =====\n",
    "# Clean accuracy\n",
    "clean_acc = evaluate(model, test_loader)\n",
    "print(f\"\\n✅ Clean Test Accuracy: {clean_acc*100:.2f}%\")\n",
    "\n",
    "# FGSM attack\n",
    "test_adversarial(\n",
    "    model, test_loader,\n",
    "    attack_fn=fgsm_attack,\n",
    "    attack_name=\"FGSM\",\n",
    "    epsilon=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# PGD attack\n",
    "test_adversarial(\n",
    "    model, test_loader,\n",
    "    attack_fn=pgd_attack,\n",
    "    attack_name=\"PGD\",\n",
    "    eps=0.1,\n",
    "    alpha=0.02,\n",
    "    iters=10,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0c1f5-8b96-4ab0-8f09-00d4f4da7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train the model again\n",
    "\n",
    "# === Load saved model for continued training ===\n",
    "model = HybridQNN(n_qubits, num_classes).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-3)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"best_QNI_model_2.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "best_val_acc = checkpoint['val_accuracy']\n",
    "print(f\"✅ Model loaded. Resuming from epoch {start_epoch} with best val_acc = {best_val_acc:.4f}\")\n",
    "\n",
    "# Resume training for 10 more epochs\n",
    "for epoch in range(start_epoch, start_epoch + 5):\n",
    "    if epoch % 5 == 0:\n",
    "        centroids = compute_centroids(model, train_loader, device, num_classes)\n",
    "\n",
    "    model.train()\n",
    "    running_loss, running_correct, running_total = 0, 0, 0\n",
    "\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch} [train]\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Clean path\n",
    "        feats = model.feature_extractor(x)\n",
    "        clean_logits = model(x)\n",
    "        loss_clean = F.cross_entropy(clean_logits, y)\n",
    "\n",
    "        # Perturbed path using gradient-based perturbation on features\n",
    "        feats_pert = gradient_noise_on_features(model, x, y, epsilon=0.1)\n",
    "        feats_pert_t = torch.tanh(feats_pert)\n",
    "        q_out_pert = torch.stack([model.q_layer(f) for f in feats_pert_t])\n",
    "        pert_logits = model.classifier(q_out_pert)\n",
    "        loss_pert = F.cross_entropy(pert_logits, y)\n",
    "\n",
    "        # Joint loss and backprop\n",
    "        loss = 0.8 * loss_clean + 0.2 * loss_pert\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # Track stats\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        running_correct += (clean_logits.argmax(1) == y).sum().item()\n",
    "        running_total += y.size(0)\n",
    "\n",
    "    # Scheduler step\n",
    "    avg_train_loss = running_loss / running_total\n",
    "    sched.step(avg_train_loss)\n",
    "\n",
    "    train_acc = running_correct / running_total\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "    print(f\"\\nEpoch {epoch:2d} — train loss: {avg_train_loss:.4f}, \"\n",
    "          f\"train acc: {train_acc:.4f}, val acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model if improved\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'val_accuracy': val_acc\n",
    "        }, \"best_QNI_model_2.pth\")\n",
    "        print(f\"✅ Best model updated at epoch {epoch} with val_acc: {val_acc:.4f}\\n\")\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc13cec6-9124-4401-987b-fd1c0e4bfb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Adialer.C       0.88      1.00      0.93        14\n",
      "     Agent.FYI       1.00      1.00      1.00        13\n",
      "     Allaple.A       1.00      0.90      0.95       296\n",
      "     Allaple.L       0.86      1.00      0.92       160\n",
      " Alueron.gen!J       1.00      0.95      0.98        21\n",
      "     Autorun.K       0.00      0.00      0.00        12\n",
      "       C2LOP.P       0.67      0.50      0.57        16\n",
      "   C2LOP.gen!g       0.69      1.00      0.82        20\n",
      "Dialplatform.B       0.95      1.00      0.98        20\n",
      "     Dontovo.A       1.00      1.00      1.00        17\n",
      "      Fakerean       1.00      0.97      0.99        39\n",
      " Instantaccess       1.00      1.00      1.00        44\n",
      "    Lolyda.AA1       0.88      0.95      0.91        22\n",
      "    Lolyda.AA2       1.00      0.86      0.92        21\n",
      "    Lolyda.AA3       0.92      0.92      0.92        13\n",
      "     Lolyda.AT       1.00      0.94      0.97        17\n",
      "   Malex.gen!J       1.00      0.87      0.93        15\n",
      " Obfuscator.AD       0.94      1.00      0.97        15\n",
      "      Rbot!gen       0.94      1.00      0.97        17\n",
      "    Skintrim.N       0.88      0.88      0.88         8\n",
      " Swizzor.gen!E       0.50      0.79      0.61        14\n",
      " Swizzor.gen!I       0.00      0.00      0.00        14\n",
      "         VB.AT       1.00      0.98      0.99        42\n",
      "    Wintrim.BX       0.69      1.00      0.81        11\n",
      "       Yuner.A       0.87      1.00      0.93        80\n",
      "\n",
      "      accuracy                           0.92       961\n",
      "     macro avg       0.83      0.86      0.84       961\n",
      "  weighted avg       0.91      0.92      0.91       961\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/netsec1/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/netsec1/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/netsec1/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "## to generate classification report \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "\n",
    "# Initialize the model\n",
    "model = HybridQNN(n_qubits=n_qubits, num_classes=num_classes).to(device)\n",
    "\n",
    "# ✅ Load raw model weights directly\n",
    "checkpoint = torch.load(\"best_adv_qni_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)  # ⬅️ Fix here\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Get class names from the test dataset\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e593f34-746b-4998-9d87-d575d774a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Clean Test Accuracy: 95.94%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ===== FGSM Attack =====\n",
    "def fgsm_attack(model, x, y, epsilon=0.1, device='cuda'):\n",
    "    model.eval()\n",
    "    x_adv = x.clone().detach().to(device).requires_grad_(True)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logits = model(x_adv)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "    x_adv = torch.clamp(x_adv, min=-1.0, max=1.0)\n",
    "    return x_adv.detach()\n",
    "\n",
    "# ===== PGD Attack =====\n",
    "def pgd_attack(model, x, y, eps=0.1, alpha=0.02, iters=10, device='cuda'):\n",
    "    model.eval()\n",
    "    x_orig = x.clone().detach().to(device)\n",
    "    x_adv  = x_orig + torch.empty_like(x_orig).uniform_(-eps, eps)\n",
    "    x_adv  = torch.clamp(x_adv, -1.0, 1.0).detach()\n",
    "\n",
    "    y = y.to(device)\n",
    "    for _ in range(iters):\n",
    "        x_adv.requires_grad_(True)\n",
    "        logits = model(x_adv)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        x_adv = x_adv + alpha * x_adv.grad.sign()\n",
    "        delta = torch.clamp(x_adv - x_orig, min=-eps, max=eps)\n",
    "        x_adv = torch.clamp(x_orig + delta, -1.0, 1.0).detach()\n",
    "    return x_adv\n",
    "\n",
    "# ===== Evaluate Attack =====\n",
    "def test_adversarial(model, loader, attack_fn, attack_name, **attack_kwargs):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack_fn(model, x, y, **attack_kwargs)\n",
    "        logits = model(x_adv)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"{attack_name} Adversarial Accuracy: {acc:.2f}%\")\n",
    "\n",
    "# ===== Load Model from best_QNI_model_2.pth =====\n",
    "model = HybridQNN(n_qubits=n_qubits, num_classes=num_classes).to(device)\n",
    "checkpoint = torch.load(\"best_QNI_model_2.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# ===== Run Evaluations =====\n",
    "# Clean accuracy\n",
    "clean_acc = evaluate(model, test_loader)\n",
    "print(f\"\\n✅ Clean Test Accuracy: {clean_acc*100:.2f}%\")\n",
    "\n",
    "# FGSM attack\n",
    "test_adversarial(\n",
    "    model, test_loader,\n",
    "    attack_fn=fgsm_attack,\n",
    "    attack_name=\"FGSM\",\n",
    "    epsilon=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# PGD attack\n",
    "test_adversarial(\n",
    "    model, test_loader,\n",
    "    attack_fn=pgd_attack,\n",
    "    attack_name=\"PGD\",\n",
    "    eps=0.1,\n",
    "    alpha=0.02,\n",
    "    iters=10,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c83cf-5974-423e-adc2-69736e5e8505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
